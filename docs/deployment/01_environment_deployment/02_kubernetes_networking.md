# â­ AIä¸­å° - Kubernetesé›†ç¾¤éƒ¨ç½²

æœ¬æ–‡æ¡£æŒ‡å¯¼å¦‚ä½•åŸºäºå·²é…ç½®çš„Dockerç¯å¢ƒéƒ¨ç½²Kubernetesé›†ç¾¤ï¼ŒåŒ…æ‹¬é›†ç¾¤åˆå§‹åŒ–ã€ç½‘ç»œé…ç½®å’ŒåŸºç¡€æœåŠ¡ã€‚

> **ğŸ“‹ å‰ç½®æ¡ä»¶**: åœ¨å¼€å§‹Kubernetesé›†ç¾¤éƒ¨ç½²ä¹‹å‰ï¼Œè¯·ç¡®ä¿å·²å®Œæˆï¼š
> - âœ… [æ“ä½œç³»ç»Ÿå®‰è£…ä¸åŸºç¡€é…ç½®](./00_os_installation_ubuntu.md)
> - âœ… [å®¹å™¨åŒ–å¹³å°éƒ¨ç½²](./01_container_platform_setup.md) - Docker Engineå·²å°±ç»ª
> - âœ… æ‰€æœ‰èŠ‚ç‚¹ç½‘ç»œäº’é€šä¸”æ»¡è¶³Kubernetesç¡¬ä»¶è¦æ±‚

## ğŸ“‘ æ–‡æ¡£ç›®å½•

- [â±ï¸ é¢„è®¡éƒ¨ç½²æ—¶é—´](#ï¸-é¢„è®¡éƒ¨ç½²æ—¶é—´)
- [ğŸ¯ éƒ¨ç½²ç›®æ ‡](#-éƒ¨ç½²ç›®æ ‡)
- [ğŸš¨ å®é™…éƒ¨ç½²ç»éªŒæ€»ç»“](#-å®é™…éƒ¨ç½²ç»éªŒæ€»ç»“)
- [1. é›†ç¾¤å‡†å¤‡å·¥ä½œ](#1-é›†ç¾¤å‡†å¤‡å·¥ä½œ)
  - [1.1 æ‰€æœ‰èŠ‚ç‚¹åŸºç¡€é…ç½®](#11-æ‰€æœ‰èŠ‚ç‚¹åŸºç¡€é…ç½®)
  - [1.2 é…ç½®Containerd for Kubernetes](#12-é…ç½®containerd-for-kubernetes)
  - [1.3 éªŒè¯ SystemdCgroup é…ç½®](#13-éªŒè¯-systemdcgroup-é…ç½®)
- [2. Kubernetesç»„ä»¶å®‰è£…](#2-kubernetesç»„ä»¶å®‰è£…)
  - [2.1 å®‰è£…kubeadmã€kubeletã€kubectl](#21-å®‰è£…kubeadmkubeletkubectl)
  - [2.2 é…ç½®kubelet](#22-é…ç½®kubelet)
- [3. é›†ç¾¤åˆå§‹åŒ–](#3-é›†ç¾¤åˆå§‹åŒ–)
  - [3.1 MasterèŠ‚ç‚¹åˆå§‹åŒ–](#31-masterèŠ‚ç‚¹åˆå§‹åŒ–)
  - [3.2 é…ç½®kubectl](#32-é…ç½®kubectl)
  - [3.3 WorkerèŠ‚ç‚¹åŠ å…¥é›†ç¾¤](#33-workerèŠ‚ç‚¹åŠ å…¥é›†ç¾¤)
  - [3.4 é›†ç¾¤åˆå§‹åŒ–æ•…éšœæ’æŸ¥](#34-é›†ç¾¤åˆå§‹åŒ–æ•…éšœæ’æŸ¥)
- [4. ç½‘ç»œæ’ä»¶éƒ¨ç½²](#4-ç½‘ç»œæ’ä»¶éƒ¨ç½²)
  - [4.1 é€‰æ‹©ç½‘ç»œæ’ä»¶](#41-é€‰æ‹©ç½‘ç»œæ’ä»¶)
  - [4.2 éƒ¨ç½²Flannelç½‘ç»œæ’ä»¶](#42-éƒ¨ç½²flannelç½‘ç»œæ’ä»¶)
  - [4.3 éƒ¨ç½²Calicoç½‘ç»œæ’ä»¶(æ›¿ä»£æ–¹æ¡ˆ)](#43-éƒ¨ç½²calicoç½‘ç»œæ’ä»¶æ›¿ä»£æ–¹æ¡ˆ)
  - [4.4 éªŒè¯ç½‘ç»œæ’ä»¶](#44-éªŒè¯ç½‘ç»œæ’ä»¶)
  - [4.5 ç½‘ç»œè¿é€šæ€§æµ‹è¯•](#45-ç½‘ç»œè¿é€šæ€§æµ‹è¯•)
  - [4.6 ç½‘ç»œæ’ä»¶æ•…éšœæ’æŸ¥](#46-ç½‘ç»œæ’ä»¶æ•…éšœæ’æŸ¥)
  - [4.7 å®Œæ•´ç½‘ç»œéªŒè¯](#47-å®Œæ•´ç½‘ç»œéªŒè¯)
  - [4.8 ç”Ÿäº§ç¯å¢ƒç½‘ç»œä¼˜åŒ–é…ç½®](#48-ç”Ÿäº§ç¯å¢ƒç½‘ç»œä¼˜åŒ–é…ç½®)
- [5. Ingressæ§åˆ¶å™¨éƒ¨ç½²](#5-ingressæ§åˆ¶å™¨éƒ¨ç½²)
  - [5.1 NGINX Ingress Controlleréƒ¨ç½²](#51-nginx-ingress-controlleréƒ¨ç½²)
  - [5.2 Ingress Controlleræ•…éšœæ’æŸ¥](#52-ingress-controlleræ•…éšœæ’æŸ¥)
  - [5.3 éªŒè¯Ingress Controller](#53-éªŒè¯ingress-controller)
  - [5.4 Ingressæµ‹è¯•åº”ç”¨](#54-ingressæµ‹è¯•åº”ç”¨)
- [6. ğŸ”’ é›†ç¾¤å®‰å…¨é…ç½®](#6--é›†ç¾¤å®‰å…¨é…ç½®)
  - [6.1 ç½‘ç»œå®‰å…¨ç­–ç•¥](#61-ç½‘ç»œå®‰å…¨ç­–ç•¥)
  - [6.2 RBACå®‰å…¨åŠ å›º](#62-rbacå®‰å…¨åŠ å›º)
  - [6.3 Podå®‰å…¨æ ‡å‡†](#63-podå®‰å…¨æ ‡å‡†)
  - [6.4 é›†ç¾¤è®¿é—®å®‰å…¨](#64-é›†ç¾¤è®¿é—®å®‰å…¨)
  - [6.5 å®šæœŸå®‰å…¨æ£€æŸ¥è„šæœ¬](#65-å®šæœŸå®‰å…¨æ£€æŸ¥è„šæœ¬)
- [7. é›†ç¾¤éªŒè¯ä¸æµ‹è¯•](#7-é›†ç¾¤éªŒè¯ä¸æµ‹è¯•)
  - [7.1 é›†ç¾¤åŸºç¡€åŠŸèƒ½éªŒè¯](#71-é›†ç¾¤åŸºç¡€åŠŸèƒ½éªŒè¯)
  - [7.2 å®Œæ•´åŠŸèƒ½æµ‹è¯•](#72-å®Œæ•´åŠŸèƒ½æµ‹è¯•)
- [8. éƒ¨ç½²æ€»ç»“](#8-éƒ¨ç½²æ€»ç»“)
  - [8.1 éƒ¨ç½²å®Œæˆæ£€æŸ¥æ¸…å•](#81-éƒ¨ç½²å®Œæˆæ£€æŸ¥æ¸…å•)
  - [8.2 å®é™…éƒ¨ç½²æ—¶é—´ç»Ÿè®¡](#82-å®é™…éƒ¨ç½²æ—¶é—´ç»Ÿè®¡)
  - [8.3 é›†ç¾¤çŠ¶æ€ç›‘æ§](#83-é›†ç¾¤çŠ¶æ€ç›‘æ§)
- [æ•…éšœæ’æŸ¥è”ç³»æ–¹å¼](#æ•…éšœæ’æŸ¥è”ç³»æ–¹å¼)
- [éƒ¨ç½²æˆåŠŸæ ‡å¿—](#éƒ¨ç½²æˆåŠŸæ ‡å¿—)

## â±ï¸ é¢„è®¡éƒ¨ç½²æ—¶é—´
- **Kubernetesç»„ä»¶å®‰è£…**: 20-30åˆ†é’Ÿ  
- **é›†ç¾¤åˆå§‹åŒ–**: 15-25åˆ†é’Ÿ
- **ç½‘ç»œæ’ä»¶é…ç½®**: 10-20åˆ†é’Ÿ
- **åŸºç¡€æœåŠ¡éƒ¨ç½²**: 15-30åˆ†é’Ÿ
- **æ€»è®¡**: 1-1.5å°æ—¶

## ğŸ¯ éƒ¨ç½²ç›®æ ‡
âœ… Kubernetes 1.28.8 é›†ç¾¤ç¯å¢ƒ  
âœ… CNIç½‘ç»œæ’ä»¶ (Flannel/Calico - åŸºäºç½‘ç»œç¯å¢ƒé€‰æ‹©)  
âœ… Ingressæ§åˆ¶å™¨ (NGINX)  
âœ… åŸºç¡€ç›‘æ§å’Œç®¡ç†å·¥å…·  
âœ… é›†ç¾¤å¥åº·éªŒè¯

## ğŸ“‹ ç‰ˆæœ¬å…¼å®¹æ€§çŸ©é˜µ

| ç»„ä»¶ | æ¨èç‰ˆæœ¬ | å…¼å®¹ç‰ˆæœ¬èŒƒå›´ | å¤‡æ³¨ |
|------|---------|-------------|------|
| **Ubuntu** | 24.04 LTS | 22.04+ | æœ¬æ–‡æ¡£åŸºäº24.04éªŒè¯ |
| **Kubernetes** | 1.28.8 | 1.28.x | ç”Ÿäº§ç¨³å®šç‰ˆæœ¬ |
| **containerd** | 1.7.x | 1.6.x+ | åŒ…å«åœ¨Dockerå®‰è£…ä¸­ |
| **Flannel** | v0.24.x | v0.22.x+ | æ¨èç”¨äºå—é™ç½‘ç»œ |
| **Calico** | v3.27.x | v3.25.x+ | æ¨èç”¨äºç”Ÿäº§ç¯å¢ƒ |
| **NGINX Ingress** | v1.9.x | v1.8.x+ | å®˜æ–¹ç»´æŠ¤ç‰ˆæœ¬ |

> **âš ï¸ ç‰ˆæœ¬å‡çº§æé†’**: 
> - Kubernetesç»„ä»¶ç‰ˆæœ¬åº”ä¿æŒä¸€è‡´æ€§
> - è·¨å¤§ç‰ˆæœ¬å‡çº§å‰è¯·å…ˆåœ¨æµ‹è¯•ç¯å¢ƒéªŒè¯
> - CNIæ’ä»¶ç‰ˆæœ¬éœ€ä¸Kubernetesç‰ˆæœ¬å…¼å®¹

## ğŸš¨ å®é™…éƒ¨ç½²ç»éªŒæ€»ç»“
> **åŸºäºå®é™…éƒ¨ç½²è¿‡ç¨‹çš„å…³é”®å‘ç° (Ubuntu 24.04 LTS + Kubernetes 1.28.8)**:
> - **ç½‘ç»œæ’ä»¶é€‰æ‹©**: åœ¨å—é™ç½‘ç»œç¯å¢ƒä¸‹ï¼ŒFlannelæ¯”Calicoæ›´ç¨³å®šå¯é 
> - **CIDRé…ç½®ä¸€è‡´æ€§**: ç¡®ä¿kubeadm initçš„--pod-network-cidrä¸ç½‘ç»œæ’ä»¶é…ç½®å®Œå…¨åŒ¹é…
> - **é•œåƒæ‹‰å–**: é…ç½®å›½å†…é•œåƒæºå¯æ˜¾è‘—æå‡éƒ¨ç½²æˆåŠŸç‡ï¼Œå»ºè®®é¢„æ‹‰å–pauseå®¹å™¨
> - **è‡ªå®šä¹‰é…ç½®**: ä½¿ç”¨æœ¬åœ°é…ç½®æ–‡ä»¶æ¯”åœ¨çº¿ä¸‹è½½æ›´å¯é 
> - **RBACæƒé™**: Ingress Controlleréƒ¨ç½²å¯èƒ½éœ€è¦é¢å¤–çš„ClusterRoleæƒé™ä¿®å¤
> - **Admission Webhook**: å»ºè®®åœ¨å—é™ç¯å¢ƒä¸­åˆ é™¤validatingwebhookconfiguration
> - **éƒ¨ç½²æ—¶é•¿**: å®é™…éƒ¨ç½²æ—¶é—´çº¦2-3å°æ—¶ï¼ŒåŒ…å«é—®é¢˜æ’æŸ¥å’Œè§£å†³

## 1. é›†ç¾¤å‡†å¤‡å·¥ä½œ

### 1.1 æ‰€æœ‰èŠ‚ç‚¹åŸºç¡€é…ç½®

åœ¨æ‰€æœ‰å°†è¦åŠ å…¥é›†ç¾¤çš„èŠ‚ç‚¹ä¸Šæ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š

```bash
# ç¦ç”¨swap (Kubernetesè¦æ±‚)
sudo swapoff -a
# æ°¸ä¹…ç¦ç”¨swap
sudo sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab

# é…ç½®å†…æ ¸æ¨¡å—
cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
overlay
br_netfilter
EOF

sudo modprobe overlay
sudo modprobe br_netfilter

# é…ç½®å†…æ ¸å‚æ•°
cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-iptables  = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward                 = 1
EOF

sudo sysctl --system

# éªŒè¯containerdå·²æ­£ç¡®é…ç½®
sudo systemctl status containerd
```

### 1.2 é…ç½®Containerd for Kubernetes

**å…³é”®é…ç½®**: ä»¥ä¸‹é…ç½®åŸºäºå®é™…éƒ¨ç½²ç»éªŒï¼Œå¯æœ‰æ•ˆè§£å†³é•œåƒæ‹‰å–å’Œpauseå®¹å™¨é—®é¢˜ã€‚

```bash
# ç”Ÿæˆcontainerdé»˜è®¤é…ç½®
sudo mkdir -p /etc/containerd
containerd config default | sudo tee /etc/containerd/config.toml

# é…ç½®containerdå›½å†…é•œåƒæº (è§£å†³é•œåƒæ‹‰å–è¶…æ—¶é—®é¢˜)
sudo tee -a /etc/containerd/config.toml <<EOF

# é…ç½®å›½å†…é•œåƒæºä»¥æå‡æ‹‰å–é€Ÿåº¦å’ŒæˆåŠŸç‡
[plugins."io.containerd.grpc.v1.cri".registry]
  config_path = ""

  [plugins."io.containerd.grpc.v1.cri".registry.auths]

  [plugins."io.containerd.grpc.v1.cri".registry.configs]

  [plugins."io.containerd.grpc.v1.cri".registry.headers]

  [plugins."io.containerd.grpc.v1.cri".registry.mirrors]
    [plugins."io.containerd.grpc.v1.cri".registry.mirrors."docker.io"]
      endpoint = ["https://registry-1.docker.io", "https://y8y5jkya.mirror.aliyuncs.com"]
    [plugins."io.containerd.grpc.v1.cri".registry.mirrors."k8s.gcr.io"]
      endpoint = ["https://registry.aliyuncs.com/google_containers"]
    [plugins."io.containerd.grpc.v1.cri".registry.mirrors."registry.k8s.io"]
      endpoint = ["https://registry.aliyuncs.com/google_containers"]
    [plugins."io.containerd.grpc.v1.cri".registry.mirrors."quay.io"]
      endpoint = ["https://quay.mirrors.ustc.edu.cn"]
EOF

# é‡å¯containerdæœåŠ¡
sudo systemctl restart containerd
sudo systemctl enable containerd

# éªŒè¯é…ç½®
sudo systemctl status containerd

# â­ é‡è¦ï¼šé¢„æ‹‰å–pauseå®¹å™¨ (è§£å†³pauseå®¹å™¨é—®é¢˜)
echo "é¢„æ‹‰å–pauseå®¹å™¨..."
sudo crictl pull registry.aliyuncs.com/google_containers/pause:3.9
sudo ctr -n k8s.io image tag registry.aliyuncs.com/google_containers/pause:3.9 registry.k8s.io/pause:3.9
```

### 1.3 éªŒè¯ SystemdCgroup é…ç½®

åœ¨é…ç½®å®Œ Containerd åï¼ŒéªŒè¯ SystemdCgroup è®¾ç½®ï¼š

```bash
# éªŒè¯ SystemdCgroup é…ç½®
grep -A 5 -B 5 "SystemdCgroup.*true" /etc/containerd/config.toml

# åº”è¯¥çœ‹åˆ°ç±»ä¼¼è¾“å‡º:
# [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options]
#   BinaryName = ""
#   ...
#   SystemdCgroup = true
```

å¦‚æœé…ç½®æ­£ç¡®ï¼Œç»§ç»­ä¸‹ä¸€æ­¥ã€‚å¦‚æœæ²¡æœ‰æ‰¾åˆ°æˆ–å€¼ä¸º falseï¼Œé‡æ–°æ‰§è¡Œï¼š

```bash
sudo sed -i 's/SystemdCgroup = false/SystemdCgroup = true/g' /etc/containerd/config.toml
sudo systemctl restart containerd
```

## 2. Kubernetesç»„ä»¶å®‰è£…

### 2.1 å®‰è£…kubeadmã€kubeletã€kubectl

```bash
# å®‰è£…å¿…è¦çš„ä¾èµ–
sudo apt-get update
sudo apt-get install -y apt-transport-https ca-certificates curl gpg

# æ·»åŠ Kuberneteså®˜æ–¹GPGå¯†é’¥
curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.28/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg

# æ·»åŠ Kubernetes APTæº
echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.28/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list

# æ›´æ–°åŒ…ç´¢å¼•
sudo apt-get update

# å®‰è£…æŒ‡å®šç‰ˆæœ¬çš„Kubernetesç»„ä»¶
KUBE_VERSION="1.28.8-1.1"
sudo apt-get install -y kubelet=${KUBE_VERSION} kubeadm=${KUBE_VERSION} kubectl=${KUBE_VERSION}

# é”å®šç‰ˆæœ¬é˜²æ­¢è‡ªåŠ¨å‡çº§
sudo apt-mark hold kubelet kubeadm kubectl

# éªŒè¯å®‰è£…
kubeadm version
kubelet --version
kubectl version --client
```

### 2.2 å›½å†…é•œåƒæºé…ç½® (å¯é€‰)

å¦‚æœç½‘ç»œè®¿é—®Kuberneteså®˜æ–¹é•œåƒæœ‰å›°éš¾ï¼Œå¯ä»¥ä½¿ç”¨é˜¿é‡Œäº‘é•œåƒæºï¼š

```bash
# âš ï¸ æ³¨æ„ï¼šå¦‚æœå®˜æ–¹æºå¯ä»¥æ­£å¸¸è®¿é—®ï¼Œå»ºè®®ä¼˜å…ˆä½¿ç”¨å®˜æ–¹æº
# ä½¿ç”¨é˜¿é‡Œäº‘é•œåƒæºä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ

# æ¸…ç†ç°æœ‰é…ç½®
sudo rm -f /etc/apt/keyrings/kubernetes-apt-keyring.gpg
sudo rm -f /etc/apt/sources.list.d/kubernetes.list

# é‡æ–°æ·»åŠ é˜¿é‡Œäº‘é•œåƒæº
curl -fsSL https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.28/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
echo "deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.28/deb/ /" | sudo tee /etc/apt/sources.list.d/kubernetes.list

# æ›´æ–°åŒ…ç´¢å¼•
sudo apt-get update

# éªŒè¯åŒ…æ˜¯å¦å¯ç”¨
apt-cache madison kubelet kubeadm kubectl

# å®‰è£…Kubernetesç»„ä»¶
KUBE_VERSION="1.28.8-1.1"
sudo apt-get install -y kubelet=${KUBE_VERSION} kubeadm=${KUBE_VERSION} kubectl=${KUBE_VERSION}
```

### 2.3 æ•…éšœæ’æŸ¥æŒ‡å—

å¦‚æœé‡åˆ°åŒ…å®‰è£…é—®é¢˜ï¼š

```bash
# é—®é¢˜1: æ— æ³•å®šä½åŒ… (Unable to locate package)
# è§£å†³æ–¹æ¡ˆ: é‡æ–°é…ç½®APTæº
sudo rm -f /etc/apt/keyrings/kubernetes-apt-keyring.gpg
sudo rm -f /etc/apt/sources.list.d/kubernetes.list

# é‡æ–°æ·»åŠ å®˜æ–¹æº
sudo mkdir -p /etc/apt/keyrings
curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.28/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.28/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list

sudo apt-get update
apt-cache search kubelet  # éªœè¯åŒ…æ˜¯å¦å¯ç”¨

# é—®é¢˜2: GPGå¯†é’¥éªŒè¯å¤±è´¥
# è§£å†³æ–¹æ¡ˆ: æ¸…ç†å¹¶é‡æ–°æ·»åŠ å¯†é’¥
sudo apt-key del $(sudo apt-key list | grep -B1 Kubernetes | head -1 | awk '{print $2}' | tr -d '/')
# ç„¶åé‡æ–°æ‰§è¡Œå¯†é’¥æ·»åŠ æ­¥éª¤

# é—®é¢˜3: ç½‘ç»œè¿æ¥é—®é¢˜
# è§£å†³æ–¹æ¡ˆ: æ£€æŸ¥ç½‘ç»œè¿æ¥
curl -I https://pkgs.k8s.io  # æµ‹è¯•å®˜æ–¹æºè¿é€šæ€§
curl -I https://mirrors.aliyun.com  # æµ‹è¯•é˜¿é‡Œäº‘æºè¿é€šæ€§
```

## 3. é›†ç¾¤åˆå§‹åŒ–

### 3.1 MasterèŠ‚ç‚¹åˆå§‹åŒ–

**ä»…åœ¨ä¸»èŠ‚ç‚¹(Control Plane)ä¸Šæ‰§è¡Œ**ï¼š

```bash
# è·å–ä¸»èŠ‚ç‚¹IPåœ°å€ (é€‰æ‹©åˆé€‚çš„ç½‘ç»œæ¥å£)
# æ–¹æ³•1: æŸ¥çœ‹æ‰€æœ‰ç½‘ç»œæ¥å£
ip addr show
# ç¤ºä¾‹è¾“å‡º:
# eno1: inet 192.168.110.88/24  (ä¸»ç½‘ç»œæ¥å£)
# eno2: inet 192.168.110.89/24  (å¤‡ç”¨ç½‘ç»œæ¥å£)

# æ–¹æ³•2: è‡ªåŠ¨è·å–ä¸»IP
MASTER_IP=$(ip route get 1 | awk '{print $7; exit}')
# æˆ–æ‰‹åŠ¨è®¾ç½® (æ ¹æ®å®é™…ç½‘ç»œç¯å¢ƒè°ƒæ•´)
MASTER_IP="192.168.110.88"  # ä½¿ç”¨å®é™…çš„ä¸»èŠ‚ç‚¹IP

# è®¾ç½®é›†ç¾¤é…ç½®å˜é‡ (â­ é‡è¦ï¼šæ­¤å¤„ä½¿ç”¨Flannelé»˜è®¤ç½‘æ®µ)
POD_NETWORK_CIDR="192.168.0.0/16"  # Flannelé»˜è®¤ç½‘æ®µï¼Œä¸ç½‘ç»œæ’ä»¶é…ç½®ä¿æŒä¸€è‡´

echo "MasterèŠ‚ç‚¹IP: $MASTER_IP"
echo "Podç½‘ç»œCIDR: $POD_NETWORK_CIDR"

# é¢„æ‹‰å–é•œåƒ (å¼ºçƒˆæ¨èï¼šé¿å…åˆå§‹åŒ–æ—¶æ‹‰å–å¤±è´¥)
sudo kubeadm config images pull --kubernetes-version=v1.28.8

# â­ å…³é”®é…ç½®ï¼šåˆå§‹åŒ–é›†ç¾¤
sudo kubeadm init \
  --pod-network-cidr=${POD_NETWORK_CIDR} \
  --kubernetes-version=v1.28.8 \
  --apiserver-advertise-address=${MASTER_IP} \
  --cri-socket=unix:///var/run/containerd/containerd.sock \
  --ignore-preflight-errors=NumCPU,Mem

# é…ç½®kubectl (åœ¨ä¸»èŠ‚ç‚¹ä¸Š)
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

# éªŒè¯é›†ç¾¤çŠ¶æ€
kubectl get nodes
kubectl get pods -A

# â­ å®é™…éƒ¨ç½²ç»éªŒï¼šæ­¤æ—¶èŠ‚ç‚¹çŠ¶æ€ä¸ºNotReadyæ˜¯æ­£å¸¸çš„ï¼Œéœ€è¦å®‰è£…ç½‘ç»œæ’ä»¶åæ‰ä¼šå˜ä¸ºReady
echo "æ³¨æ„ï¼šèŠ‚ç‚¹çŠ¶æ€ä¸ºNotReadyæ˜¯æ­£å¸¸çš„ï¼Œå®‰è£…ç½‘ç»œæ’ä»¶åä¼šå˜ä¸ºReady"
```

**é‡è¦**: ä¿å­˜åˆå§‹åŒ–è¾“å‡ºä¸­çš„`kubeadm join`å‘½ä»¤ï¼Œç”¨äºæ·»åŠ å·¥ä½œèŠ‚ç‚¹ã€‚

### ğŸš¨ é›†ç¾¤åˆå§‹åŒ–å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

åŸºäºå®é™…éƒ¨ç½²ç»éªŒï¼Œä»¥ä¸‹æ˜¯å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆï¼š

```bash
# é—®é¢˜1: pauseå®¹å™¨æ‹‰å–å¤±è´¥
# é”™è¯¯ä¿¡æ¯: failed to pull image "registry.k8s.io/pause:3.9"
# è§£å†³æ–¹æ¡ˆ: é¢„æ‹‰å–å¹¶æ ‡è®°pauseå®¹å™¨
sudo crictl pull registry.aliyuncs.com/google_containers/pause:3.9
sudo ctr -n k8s.io image tag registry.aliyuncs.com/google_containers/pause:3.9 registry.k8s.io/pause:3.9

# é—®é¢˜2: kubeadm init è¶…æ—¶
# è§£å†³æ–¹æ¡ˆ: å¢åŠ è¶…æ—¶æ—¶é—´å¹¶å¿½ç•¥é¢„æ£€æŸ¥
sudo kubeadm init \
  --pod-network-cidr=${POD_NETWORK_CIDR} \
  --kubernetes-version=v1.28.8 \
  --apiserver-advertise-address=${MASTER_IP} \
  --cri-socket=unix:///var/run/containerd/containerd.sock \
  --ignore-preflight-errors=NumCPU,Mem \
  --v=5  # å¢åŠ æ—¥å¿—è¯¦ç»†ç¨‹åº¦

# é—®é¢˜3: åˆå§‹åŒ–å¤±è´¥åé‡è¯•
# è§£å†³æ–¹æ¡ˆ: é‡ç½®é›†ç¾¤çŠ¶æ€
sudo kubeadm reset --cri-socket=unix:///var/run/containerd/containerd.sock
sudo systemctl restart containerd
sudo systemctl restart kubelet
# ç„¶åé‡æ–°æ‰§è¡Œkubeadm init

# é—®é¢˜4: éªŒè¯åˆå§‹åŒ–æ˜¯å¦æˆåŠŸ
# æ£€æŸ¥å…³é”®ç»„ä»¶æ˜¯å¦å¯åŠ¨
kubectl get pods -n kube-system
# åº”è¯¥çœ‹åˆ°: kube-apiserver, etcd, kube-controller-manager, kube-scheduler, coredns
```

### 3.2 WorkerèŠ‚ç‚¹åŠ å…¥é›†ç¾¤

åœ¨æ¯ä¸ªå·¥ä½œèŠ‚ç‚¹ä¸Šæ‰§è¡Œåˆå§‹åŒ–æ—¶è¾“å‡ºçš„joinå‘½ä»¤ï¼š

```bash
# ç¤ºä¾‹å‘½ä»¤ (å®é™…ä½¿ç”¨kubeadm initè¾“å‡ºçš„å‘½ä»¤)
sudo kubeadm join <MASTER_IP>:6443 --token <TOKEN> \
    --discovery-token-ca-cert-hash sha256:<HASH> \
    --cri-socket=unix:///var/run/containerd/containerd.sock
```

## 4. ç½‘ç»œæ’ä»¶éƒ¨ç½² - ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ

### 4.1 ç½‘ç»œæ’ä»¶é€‰æ‹©æŒ‡å—

åŸºäºå®é™…éƒ¨ç½²ç»éªŒï¼Œä¸åŒç½‘ç»œç¯å¢ƒçš„æ¨èæ–¹æ¡ˆï¼š

| ç½‘ç»œç¯å¢ƒ | æ¨èæ’ä»¶ | åŸå›  | é€‚ç”¨åœºæ™¯ |
|---------|---------|------|---------|
| **å—é™ç½‘ç»œ/å†…ç½‘** | Flannel | é…ç½®ç®€å•ã€ç¨³å®šæ€§é«˜ã€èµ„æºå ç”¨å°‘ | ä¼ä¸šå†…ç½‘ã€å¼€å‘æµ‹è¯•ç¯å¢ƒ |
| **å…¬æœ‰äº‘/å¼€æ”¾ç½‘ç»œ** | Calico | åŠŸèƒ½ä¸°å¯Œã€ç½‘ç»œç­–ç•¥æ”¯æŒ | ç”Ÿäº§ç¯å¢ƒã€éœ€è¦ç½‘ç»œéš”ç¦» |
| **é«˜æ€§èƒ½éœ€æ±‚** | Cilium | åŸºäºeBPFã€æ€§èƒ½ä¼˜å¼‚ | å¤§è§„æ¨¡ç”Ÿäº§ç¯å¢ƒ |

### 4.2 Flannel CNIå®‰è£… (æ¨èï¼šå—é™ç½‘ç»œç¯å¢ƒ)

åŸºäºå®é™…éƒ¨ç½²æˆåŠŸç»éªŒï¼ŒFlannelåœ¨å—é™ç½‘ç»œç¯å¢ƒä¸‹è¡¨ç°æœ€ä½³ï¼š

```bash
# æ–¹æ¡ˆA: åœ¨çº¿å®‰è£… (ç½‘ç»œç¯å¢ƒè‰¯å¥½æ—¶)
kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml

# æ–¹æ¡ˆB: ç¦»çº¿å®‰è£… (æ¨èï¼šé¿å…ç½‘ç»œé—®é¢˜)
# 1. ä¸‹è½½å¹¶è‡ªå®šä¹‰Flannelé…ç½®
curl -o kube-flannel.yml https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml

# 2. ä¿®æ”¹ç½‘ç»œé…ç½®ä»¥åŒ¹é…é›†ç¾¤CIDR
# é‡è¦ï¼šç¡®ä¿ä¸kubeadm initæ—¶çš„--pod-network-cidrå‚æ•°ä¸€è‡´
sed -i 's|"Network": "10.244.0.0/16"|"Network": "192.168.0.0/16"|g' kube-flannel.yml

# 3. åº”ç”¨é…ç½®
kubectl apply -f kube-flannel.yml

# 4. éªŒè¯éƒ¨ç½²
kubectl get pods -n kube-flannel
kubectl get nodes  # èŠ‚ç‚¹çŠ¶æ€åº”è¯¥å˜ä¸ºReady
```

### 4.3 è‡ªå®šä¹‰Flannelé…ç½®æ–‡ä»¶ (ç”Ÿäº§ç¯å¢ƒæ¨è)

åˆ›å»ºå®Œå…¨è‡ªå®šä¹‰çš„Flannelé…ç½®ï¼Œé¿å…ç½‘ç»œä¸‹è½½é—®é¢˜ï¼š

```bash
# åˆ›å»ºè‡ªå®šä¹‰Flannelé…ç½®
cat <<EOF | kubectl apply -f -
---
apiVersion: v1
kind: Namespace
metadata:
  labels:
    k8s-app: flannel
    pod-security.kubernetes.io/enforce: privileged
  name: kube-flannel
---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    k8s-app: flannel
  name: flannel
  namespace: kube-flannel
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    k8s-app: flannel
  name: flannel
rules:
- apiGroups:
  - ""
  resources:
  - pods
  verbs:
  - get
- apiGroups:
  - ""
  resources:
  - nodes
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - nodes/status
  verbs:
  - patch
- apiGroups:
  - networking.k8s.io
  resources:
  - clustercidrs
  verbs:
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    k8s-app: flannel
  name: flannel
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: flannel
subjects:
- kind: ServiceAccount
  name: flannel
  namespace: kube-flannel
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: kube-flannel-cfg
  namespace: kube-flannel
  labels:
    tier: node
    k8s-app: flannel
    app: flannel
data:
  cni-conf.json: |
    {
      "name": "cbr0",
      "cniVersion": "0.3.1",
      "plugins": [
        {
          "type": "flannel",
          "delegate": {
            "hairpinMode": true,
            "isDefaultGateway": true
          }
        },
        {
          "type": "portmap",
          "capabilities": {
            "portMappings": true
          }
        }
      ]
    }
  net-conf.json: |
    {
      "Network": "192.168.0.0/16",
      "Backend": {
        "Type": "vxlan"
      }
    }
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: kube-flannel-ds
  namespace: kube-flannel
  labels:
    tier: node
    app: flannel
    k8s-app: flannel
spec:
  selector:
    matchLabels:
      app: flannel
  template:
    metadata:
      labels:
        tier: node
        app: flannel
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: kubernetes.io/os
                operator: In
                values:
                - linux
      hostNetwork: true
      priorityClassName: system-node-critical
      tolerations:
      - operator: Exists
        effect: NoSchedule
      serviceAccountName: flannel
      initContainers:
      - name: install-cni-plugin
        image: docker.io/flannel/flannel-cni-plugin:v1.2.0
        command:
        - cp
        args:
        - -f
        - /flannel
        - /opt/cni/bin/flannel
        volumeMounts:
        - name: cni-plugin
          mountPath: /opt/cni/bin
      - name: install-cni
        image: docker.io/flannel/flannel:v0.22.3
        command:
        - cp
        args:
        - -f
        - /etc/kube-flannel/cni-conf.json
        - /etc/cni/net.d/10-flannel.conflist
        volumeMounts:
        - name: cni
          mountPath: /etc/cni/net.d
        - name: flannel-cfg
          mountPath: /etc/kube-flannel/
      containers:
      - name: kube-flannel
        image: docker.io/flannel/flannel:v0.22.3
        command:
        - /opt/bin/flanneld
        args:
        - --ip-masq
        - --kube-subnet-mgr
        resources:
          requests:
            cpu: "100m"
            memory: "50Mi"
        securityContext:
          privileged: false
          capabilities:
            add: ["NET_ADMIN", "NET_RAW"]
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: EVENT_QUEUE_DEPTH
          value: "5000"
        volumeMounts:
        - name: run
          mountPath: /run/flannel
        - name: flannel-cfg
          mountPath: /etc/kube-flannel/
        - name: xtables-lock
          mountPath: /run/xtables.lock
      volumes:
      - name: run
        hostPath:
          path: /run/flannel
      - name: cni-plugin
        hostPath:
          path: /opt/cni/bin
      - name: cni
        hostPath:
          path: /etc/cni/net.d
      - name: flannel-cfg
        configMap:
          name: kube-flannel-cfg
      - name: xtables-lock
        hostPath:
          path: /run/xtables.lock
          type: FileOrCreate
EOF

# ç­‰å¾…Flannel Podå¯åŠ¨
echo "ç­‰å¾…Flannel Podå¯åŠ¨..."
kubectl wait --for=condition=ready pod -l app=flannel -n kube-flannel --timeout=300s

# éªŒè¯å®‰è£…
kubectl get pods -n kube-flannel -o wide
kubectl get nodes -o wide
```

### 4.4 Calico CNIå®‰è£… (å¤‡é€‰æ–¹æ¡ˆ)

å¦‚æœç½‘ç»œç¯å¢ƒå…è®¸ä¸”éœ€è¦ç½‘ç»œç­–ç•¥åŠŸèƒ½ï¼š

```bash
# ä¸‹è½½Calico Operator
kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.27.0/manifests/tigera-operator.yaml

# åˆ›å»ºCalicoå®‰è£…é…ç½®
cat <<EOF | kubectl apply -f -
apiVersion: operator.tigera.io/v1
kind: Installation
metadata:
  name: default
spec:
  calicoNetwork:
    ipPools:
    - blockSize: 26
      cidr: 192.168.0.0/16  # æ³¨æ„ï¼šå¿…é¡»ä¸kubeadm initçš„--pod-network-cidrä¸€è‡´
      encapsulation: VXLANCrossSubnet
      natOutgoing: Enabled
      nodeSelector: all()
---
apiVersion: operator.tigera.io/v1
kind: APIServer
metadata:
  name: default
spec: {}
EOF

# ç­‰å¾…Calico Podså¯åŠ¨
echo "ç­‰å¾…Calico Podså¯åŠ¨..."
kubectl wait --for=condition=ready pod -l k8s-app=calico-node -n calico-system --timeout=300s

# éªŒè¯Calicoå®‰è£…
kubectl get pods -n calico-system
kubectl get nodes -o wide
```

### 4.5 ç½‘ç»œæ’ä»¶æ•…éšœæ’æŸ¥

åŸºäºå®é™…éƒ¨ç½²ç»éªŒçš„æ•…éšœæ’æŸ¥æ–¹æ³•ï¼š

```bash
# é—®é¢˜1: ç½‘ç»œæ’ä»¶Podå¤„äºCrashLoopBackOffçŠ¶æ€
# æ£€æŸ¥Podæ—¥å¿—
kubectl logs -n kube-flannel -l app=flannel
kubectl logs -n calico-system -l k8s-app=calico-node

# å¸¸è§åŸå› 1: CIDRé…ç½®ä¸åŒ¹é…
# æ£€æŸ¥é›†ç¾¤CIDRé…ç½®
kubectl cluster-info dump | grep -i cluster-cidr
kubectl get nodes -o yaml | grep podCIDR

# å¸¸è§åŸå› 2: ç½‘ç»œæ’ä»¶é…ç½®é”™è¯¯
# æ£€æŸ¥ConfigMapé…ç½®
kubectl get configmap -n kube-flannel kube-flannel-cfg -o yaml
kubectl describe configmap -n kube-flannel kube-flannel-cfg

# é—®é¢˜2: èŠ‚ç‚¹çŠ¶æ€ä¸€ç›´æ˜¯NotReady
# æ£€æŸ¥kubeletæ—¥å¿—
sudo journalctl -u kubelet -f --no-pager

# æ£€æŸ¥å®¹å™¨è¿è¡Œæ—¶çŠ¶æ€
sudo systemctl status containerd
sudo crictl pods

# é—®é¢˜3: Podé—´ç½‘ç»œä¸é€š
# æ£€æŸ¥iptablesè§„åˆ™
sudo iptables -t nat -L | grep KUBE
sudo iptables -L | grep KUBE

# æ£€æŸ¥ç½‘ç»œæ¥å£
ip route show
ip addr show flannel.1  # Flannelç½‘ç»œæ¥å£
```

### 4.6 ç½‘ç»œæ’ä»¶åˆ‡æ¢æŒ‡å—

å¦‚æœéœ€è¦ä»ä¸€ç§ç½‘ç»œæ’ä»¶åˆ‡æ¢åˆ°å¦ä¸€ç§ï¼š

```bash
# åˆ‡æ¢ç½‘ç»œæ’ä»¶çš„å®‰å…¨æ­¥éª¤
# 1. å¤‡ä»½ç°æœ‰é…ç½®
kubectl get all -A > cluster-backup-$(date +%Y%m%d).yaml

# 2. å¸è½½å½“å‰ç½‘ç»œæ’ä»¶
# å¸è½½Calico
kubectl delete -f https://raw.githubusercontent.com/projectcalico/calico/v3.27.0/manifests/tigera-operator.yaml

# å¸è½½Flannel
kubectl delete -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml
# æˆ–ä½¿ç”¨è‡ªå®šä¹‰é…ç½®æ–‡ä»¶å¸è½½
kubectl delete -f kube-flannel.yml

# 3. æ¸…ç†ç½‘ç»œé…ç½®
sudo ip link delete flannel.1  # åˆ é™¤Flannelæ¥å£
sudo ip link delete cali+  # åˆ é™¤Calicoæ¥å£ï¼ˆå¦‚æœå­˜åœ¨ï¼‰

# 4. é‡ç½®ç½‘ç»œé…ç½®
sudo systemctl restart containerd
sudo systemctl restart kubelet

# 5. é‡æ–°éƒ¨ç½²æ–°çš„ç½‘ç»œæ’ä»¶
# å‚è€ƒä¸Šè¿°ç›¸åº”æ’ä»¶çš„éƒ¨ç½²æ­¥éª¤

# 6. éªŒè¯åˆ‡æ¢ç»“æœ
kubectl get nodes
kubectl get pods -A
```

### 4.7 ç½‘ç»œè¿é€šæ€§æµ‹è¯•

éƒ¨ç½²ç½‘ç»œæ’ä»¶åçš„å®Œæ•´éªŒè¯æµç¨‹ï¼š

```bash
# åˆ›å»ºæµ‹è¯•Pod
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: network-test-1
  namespace: default
spec:
  containers:
  - name: test
    image: busybox:1.35
    command: ["/bin/sh", "-c", "sleep 3600"]
---
apiVersion: v1
kind: Pod
metadata:
  name: network-test-2
  namespace: default
spec:
  containers:
  - name: test
    image: busybox:1.35
    command: ["/bin/sh", "-c", "sleep 3600"]
EOF

# ç­‰å¾…Podå¯åŠ¨
kubectl wait --for=condition=ready pod network-test-1 --timeout=60s
kubectl wait --for=condition=ready pod network-test-2 --timeout=60s

# è·å–Pod IPåœ°å€
POD_IP_1=$(kubectl get pod network-test-1 -o jsonpath='{.status.podIP}')
POD_IP_2=$(kubectl get pod network-test-2 -o jsonpath='{.status.podIP}')

echo "Pod 1 IP: $POD_IP_1"
echo "Pod 2 IP: $POD_IP_2"

# æµ‹è¯•Podé—´ç½‘ç»œè¿é€šæ€§
echo "æµ‹è¯•Podé—´ç½‘ç»œè¿é€šæ€§..."
kubectl exec network-test-1 -- ping -c 3 $POD_IP_2
kubectl exec network-test-2 -- ping -c 3 $POD_IP_1

# æµ‹è¯•DNSè§£æ
echo "æµ‹è¯•DNSè§£æ..."
kubectl exec network-test-1 -- nslookup kubernetes.default
kubectl exec network-test-1 -- nslookup network-test-2.default.svc.cluster.local

# æµ‹è¯•å¤–ç½‘è¿é€šæ€§
echo "æµ‹è¯•å¤–ç½‘è¿é€šæ€§..."
kubectl exec network-test-1 -- ping -c 3 8.8.8.8
kubectl exec network-test-1 -- nslookup www.baidu.com

# æ¸…ç†æµ‹è¯•èµ„æº
kubectl delete pod network-test-1 network-test-2
```

### 4.8 ç”Ÿäº§ç¯å¢ƒç½‘ç»œä¼˜åŒ–é…ç½®

åŸºäºå®é™…éƒ¨ç½²ç»éªŒçš„æ€§èƒ½ä¼˜åŒ–å»ºè®®ï¼š

```bash
# 1. ä¼˜åŒ–Flannelæ€§èƒ½é…ç½®
# ä¿®æ”¹kube-flannelé…ç½®ï¼Œå¢åŠ æ€§èƒ½å‚æ•°
kubectl patch configmap kube-flannel-cfg -n kube-flannel --patch='
data:
  net-conf.json: |
    {
      "Network": "192.168.0.0/16",
      "Backend": {
        "Type": "vxlan",
        "VNI": 1,
        "Port": 8472,
        "GBP": true,
        "Learning": false
      }
    }'

# 2. é…ç½®Podç½‘ç»œèµ„æºé™åˆ¶
kubectl patch daemonset kube-flannel-ds -n kube-flannel --patch='
spec:
  template:
    spec:
      containers:
      - name: kube-flannel
        resources:
          limits:
            cpu: "500m"
            memory: "200Mi"
          requests:
            cpu: "100m"
            memory: "100Mi"'

# 3. ä¼˜åŒ–å†…æ ¸ç½‘ç»œå‚æ•°
sudo tee /etc/sysctl.d/k8s-network.conf <<EOF
# å¢åŠ ç½‘ç»œè¿æ¥æ•°
net.core.somaxconn = 32768
net.core.netdev_max_backlog = 5000

# ä¼˜åŒ–TCPæ€§èƒ½
net.ipv4.tcp_max_syn_backlog = 8192
net.ipv4.tcp_congestion_control = bbr

# è°ƒæ•´iptablesæ€§èƒ½
net.netfilter.nf_conntrack_max = 1048576
net.netfilter.nf_conntrack_tcp_timeout_established = 86400
EOF

sudo sysctl -p /etc/sysctl.d/k8s-network.conf
```

## 5. Ingressæ§åˆ¶å™¨éƒ¨ç½²

### 5.1 NGINX Ingress Controller

**åŸºäºå®é™…éƒ¨ç½²ç»éªŒçš„å®Œæ•´è§£å†³æ–¹æ¡ˆ**ï¼š

```bash
# æ–¹æ³•1: æ ‡å‡†éƒ¨ç½² (æ¨èå…ˆå°è¯•)
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.8.4/deploy/static/provider/baremetal/deploy.yaml

# ç­‰å¾…Ingress Controllerå¯åŠ¨
kubectl wait --namespace ingress-nginx \
  --for=condition=ready pod \
  --selector=app.kubernetes.io/component=controller \
  --timeout=300s

# éªŒè¯å®‰è£…
kubectl get pods -n ingress-nginx
kubectl get svc -n ingress-nginx
```

### ğŸš¨ Ingress Controlleréƒ¨ç½²é—®é¢˜è§£å†³æ–¹æ¡ˆ

åŸºäºå®é™…éƒ¨ç½²ç»éªŒï¼ŒNGINX Ingress Controllerå¯èƒ½é‡åˆ°ä»¥ä¸‹é—®é¢˜ï¼š

#### é—®é¢˜1: RBACæƒé™ä¸è¶³

```bash
# ç—‡çŠ¶: Ingress Controller Podå¤„äºCrashLoopBackOffçŠ¶æ€
# é”™è¯¯æ—¥å¿—: forbidden: User "system:serviceaccount:ingress-nginx:ingress-nginx" cannot...

# è§£å†³æ–¹æ¡ˆ: ä¿®å¤ClusterRoleæƒé™
kubectl patch clusterrole ingress-nginx --type='merge' -p='
{
  "rules": [
    {
      "apiGroups": [""],
      "resources": ["configmaps", "endpoints", "nodes", "pods", "secrets", "namespaces"],
      "verbs": ["list", "watch"]
    },
    {
      "apiGroups": ["coordination.k8s.io"],
      "resources": ["leases"],
      "verbs": ["list", "watch"]
    },
    {
      "apiGroups": [""],
      "resources": ["nodes"],
      "verbs": ["get"]
    },
    {
      "apiGroups": [""],
      "resources": ["services"],
      "verbs": ["get", "list", "watch"]
    },
    {
      "apiGroups": ["networking.k8s.io"],
      "resources": ["ingresses"],
      "verbs": ["get", "list", "watch"]
    },
    {
      "apiGroups": [""],
      "resources": ["events"],
      "verbs": ["create", "patch"]
    },
    {
      "apiGroups": ["networking.k8s.io"],
      "resources": ["ingresses/status"],
      "verbs": ["update"]
    },
    {
      "apiGroups": ["networking.k8s.io"],
      "resources": ["ingressclasses"],
      "verbs": ["get", "list", "watch"]
    },
    {
      "apiGroups": ["discovery.k8s.io"],
      "resources": ["endpointslices"],
      "verbs": ["list", "watch", "get"]
    }
  ]
}'

# é‡å¯Ingress Controller
kubectl rollout restart deployment ingress-nginx-controller -n ingress-nginx
```

#### é—®é¢˜2: Admission Webhooké…ç½®é—®é¢˜

```bash
# ç—‡çŠ¶: Ingressèµ„æºåˆ›å»ºå¤±è´¥
# é”™è¯¯ä¿¡æ¯: Internal error occurred: failed calling webhook "validate.nginx.ingress.kubernetes.io"

# è§£å†³æ–¹æ¡ˆ: åˆ é™¤æœ‰é—®é¢˜çš„ValidatingWebhookConfiguration
kubectl delete validatingwebhookconfiguration ingress-nginx-admission

# éªŒè¯åˆ é™¤ç»“æœ
kubectl get validatingwebhookconfiguration | grep ingress

# å¦‚æœéœ€è¦ï¼Œä¹Ÿå¯ä»¥åˆ é™¤MutatingWebhookConfiguration
kubectl delete mutatingwebhookconfiguration ingress-nginx-admission 2>/dev/null || true
```

#### é—®é¢˜3: ç®€åŒ–ç‰ˆIngress Controlleréƒ¨ç½²

å¦‚æœæ ‡å‡†éƒ¨ç½²é‡åˆ°é—®é¢˜ï¼Œå¯ä»¥ä½¿ç”¨ç®€åŒ–ç‰ˆé…ç½®ï¼š

```bash
# åˆ›å»ºç®€åŒ–ç‰ˆIngress Controlleré…ç½®
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Namespace
metadata:
  name: ingress-nginx
  labels:
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: ingress-nginx
---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/component: controller
  name: ingress-nginx
  namespace: ingress-nginx
automountServiceAccountToken: true
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: ingress-nginx
  name: ingress-nginx
rules:
  - apiGroups:
      - ""
    resources:
      - configmaps
      - endpoints
      - nodes
      - pods
      - secrets
      - namespaces
    verbs:
      - list
      - watch
  - apiGroups:
      - coordination.k8s.io
    resources:
      - leases
    verbs:
      - list
      - watch
  - apiGroups:
      - ""
    resources:
      - nodes
    verbs:
      - get
  - apiGroups:
      - ""
    resources:
      - services
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - networking.k8s.io
    resources:
      - ingresses
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - ""
    resources:
      - events
    verbs:
      - create
      - patch
  - apiGroups:
      - networking.k8s.io
    resources:
      - ingresses/status
    verbs:
      - update
  - apiGroups:
      - networking.k8s.io
    resources:
      - ingressclasses
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - discovery.k8s.io
    resources:
      - endpointslices
    verbs:
      - list
      - watch
      - get
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: ingress-nginx
  name: ingress-nginx
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: ingress-nginx
subjects:
  - kind: ServiceAccount
    name: ingress-nginx
    namespace: ingress-nginx
---
apiVersion: v1
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/component: controller
  name: ingress-nginx-controller
  namespace: ingress-nginx
data:
  allow-snippet-annotations: "true"
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/component: controller
  name: ingress-nginx-controller
  namespace: ingress-nginx
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: ingress-nginx
      app.kubernetes.io/instance: ingress-nginx
      app.kubernetes.io/component: controller
  template:
    metadata:
      labels:
        app.kubernetes.io/name: ingress-nginx
        app.kubernetes.io/instance: ingress-nginx
        app.kubernetes.io/component: controller
    spec:
      dnsPolicy: ClusterFirst
      containers:
        - name: controller
          image: registry.k8s.io/ingress-nginx/controller:v1.8.4
          imagePullPolicy: IfNotPresent
          args:
            - /nginx-ingress-controller
            - --election-id=ingress-controller-leader
            - --controller-class=k8s.io/ingress-nginx
            - --ingress-class=nginx
            - --configmap=$(POD_NAMESPACE)/ingress-nginx-controller
            - --validating-webhook=:8443
            - --validating-webhook-certificate=/usr/local/certificates/cert
            - --validating-webhook-key=/usr/local/certificates/key
            - --watch-ingress-without-class=true
          securityContext:
            capabilities:
              drop:
                - ALL
              add:
                - NET_BIND_SERVICE
            runAsUser: 101
            allowPrivilegeEscalation: true
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: LD_PRELOAD
              value: /usr/local/lib/libmimalloc.so
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /healthz
              port: 10254
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 10254
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          ports:
            - name: http
              containerPort: 80
              protocol: TCP
            - name: https
              containerPort: 443
              protocol: TCP
            - name: webhook
              containerPort: 8443
              protocol: TCP
          resources:
            requests:
              cpu: 100m
              memory: 90Mi
      nodeSelector:
        kubernetes.io/os: linux
      serviceAccountName: ingress-nginx
      terminationGracePeriodSeconds: 300
---
apiVersion: networking.k8s.io/v1
kind: IngressClass
metadata:
  labels:
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/component: controller
  name: nginx
spec:
  controller: k8s.io/ingress-nginx
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/component: controller
  name: ingress-nginx-controller
  namespace: ingress-nginx
spec:
  type: NodePort
  ports:
    - name: http
      port: 80
      protocol: TCP
      targetPort: http
    - name: https
      port: 443
      protocol: TCP
      targetPort: https
  selector:
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/component: controller
EOF

# ç­‰å¾…éƒ¨ç½²å®Œæˆ
kubectl wait --namespace ingress-nginx \
  --for=condition=ready pod \
  --selector=app.kubernetes.io/component=controller \
  --timeout=300s
```

### 5.2 é…ç½®IngressæœåŠ¡å’Œç«¯å£ä¿¡æ¯

```bash
# éªŒè¯Ingress Controlleréƒ¨ç½²çŠ¶æ€
kubectl get pods -n ingress-nginx -o wide
kubectl get svc -n ingress-nginx

# è·å–Ingress Controllerçš„NodePortç«¯å£
INGRESS_HTTP_PORT=$(kubectl get svc ingress-nginx-controller -n ingress-nginx -o jsonpath='{.spec.ports[?(@.name=="http")].nodePort}')
INGRESS_HTTPS_PORT=$(kubectl get svc ingress-nginx-controller -n ingress-nginx -o jsonpath='{.spec.ports[?(@.name=="https")].nodePort}')

echo "NGINX Ingressè®¿é—®ä¿¡æ¯:"
echo "HTTPç«¯å£: $INGRESS_HTTP_PORT"
echo "HTTPSç«¯å£: $INGRESS_HTTPS_PORT"
echo "è®¿é—®åœ°å€: http://192.168.110.88:$INGRESS_HTTP_PORT"
echo "HTTPSåœ°å€: https://192.168.110.88:$INGRESS_HTTPS_PORT"

# æµ‹è¯•Ingress Controllerå“åº”
echo "æµ‹è¯•Ingress Controllerå“åº”..."
curl -I http://192.168.110.88:$INGRESS_HTTP_PORT || echo "Ingress Controllerå°šæœªå®Œå…¨å¯åŠ¨ï¼Œè¯·ç¨ç­‰..."
```

### 5.3 Ingress ControllerçŠ¶æ€éªŒè¯

```bash
# å®Œæ•´éªŒè¯è„šæœ¬
cat <<'EOF' > verify-ingress.sh
#!/bin/bash
echo "=== NGINX Ingress Controller çŠ¶æ€éªŒè¯ ==="

# 1. æ£€æŸ¥PodçŠ¶æ€
echo "1. Ingress Controller PodçŠ¶æ€:"
kubectl get pods -n ingress-nginx -o wide

# 2. æ£€æŸ¥ServiceçŠ¶æ€
echo -e "\n2. Ingress Controller ServiceçŠ¶æ€:"
kubectl get svc -n ingress-nginx -o wide

# 3. æ£€æŸ¥ç«¯å£ä¿¡æ¯
echo -e "\n3. è®¿é—®ç«¯å£ä¿¡æ¯:"
HTTP_PORT=$(kubectl get svc ingress-nginx-controller -n ingress-nginx -o jsonpath='{.spec.ports[?(@.name=="http")].nodePort}')
HTTPS_PORT=$(kubectl get svc ingress-nginx-controller -n ingress-nginx -o jsonpath='{.spec.ports[?(@.name=="https")].nodePort}')
echo "HTTPç«¯å£: $HTTP_PORT"
echo "HTTPSç«¯å£: $HTTPS_PORT"

# 4. æ£€æŸ¥IngressClass
echo -e "\n4. IngressClassçŠ¶æ€:"
kubectl get ingressclass

# 5. æµ‹è¯•è¿é€šæ€§
echo -e "\n5. è¿é€šæ€§æµ‹è¯•:"
if curl -s -o /dev/null -w "%{http_code}" http://localhost:$HTTP_PORT --connect-timeout 5; then
    echo "âœ… Ingress Controllerå“åº”æ­£å¸¸"
else
    echo "âŒ Ingress Controlleræ— å“åº”ï¼Œè¯·æ£€æŸ¥é…ç½®"
fi

echo -e "\n=== éªŒè¯å®Œæˆ ==="
EOF

chmod +x verify-ingress.sh
./verify-ingress.sh
```

## 6. åŸºç¡€æœåŠ¡éƒ¨ç½²

### 6.1 Kubernetes Dashboard (å¯é€‰)

```bash
# éƒ¨ç½²Kubernetes Dashboard
kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.7.0/aio/deploy/recommended.yaml

# åˆ›å»ºç®¡ç†å‘˜ç”¨æˆ·
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: ServiceAccount
metadata:
  name: admin-user
  namespace: kubernetes-dashboard
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: admin-user
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: ServiceAccount
  name: admin-user
  namespace: kubernetes-dashboard
EOF

# è·å–Dashboardè®¿é—®Token
kubectl -n kubernetes-dashboard create token admin-user
```

### 6.2 MetalLBè´Ÿè½½å‡è¡¡å™¨ (å¯é€‰)

å¦‚æœåœ¨è£¸æœºç¯å¢ƒä¸­éœ€è¦LoadBalanceræœåŠ¡ï¼š

```bash
# éƒ¨ç½²MetalLB
kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.13.12/config/manifests/metallb-native.yaml

# ç­‰å¾…MetalLBå¯åŠ¨
kubectl wait --namespace metallb-system \
  --for=condition=ready pod \
  --selector=app=metallb \
  --timeout=300s

# é…ç½®IPåœ°å€æ±  (è¯·æ ¹æ®å®é™…ç½‘ç»œç¯å¢ƒè°ƒæ•´)
cat <<EOF | kubectl apply -f -
apiVersion: metallb.io/v1beta1
kind: IPAddressPool
metadata:
  name: ai-platform-pool
  namespace: metallb-system
spec:
  addresses:
  - 192.168.110.200-192.168.110.250  # åŸºäºæˆ‘ä»¬çš„å®é™…ç½‘æ®µ 192.168.110.0/24
---
apiVersion: metallb.io/v1beta1
kind: L2Advertisement
metadata:
  name: ai-platform-l2
  namespace: metallb-system
spec:
  ipAddressPools:
  - ai-platform-pool
EOF
```

## 7. é›†ç¾¤éªŒè¯å’Œæµ‹è¯•

### 7.1 é›†ç¾¤çŠ¶æ€æ£€æŸ¥

åˆ›å»ºé›†ç¾¤æ£€æŸ¥è„šæœ¬ï¼š

```bash
# åˆ›å»ºé›†ç¾¤æ£€æŸ¥è„šæœ¬
sudo tee /usr/local/bin/check-k8s-cluster.sh << 'EOF'
#!/bin/bash

echo "=== Kubernetes é›†ç¾¤çŠ¶æ€æ£€æŸ¥ ==="
echo

echo "é›†ç¾¤èŠ‚ç‚¹çŠ¶æ€:"
kubectl get nodes -o wide
echo

echo "ç³»ç»ŸPodçŠ¶æ€:"
kubectl get pods -A | grep -E "(kube-system|calico-system|ingress-nginx)"
echo

echo "é›†ç¾¤ç»„ä»¶çŠ¶æ€:"
kubectl get componentstatuses
echo

echo "é›†ç¾¤èµ„æºä½¿ç”¨æƒ…å†µ:"
kubectl top nodes 2>/dev/null || echo "Metrics Serveræœªå®‰è£…"
echo

echo "ç½‘ç»œæ’ä»¶çŠ¶æ€:"
kubectl get pods -n calico-system -o wide
echo

echo "Ingressæ§åˆ¶å™¨çŠ¶æ€:"
kubectl get pods -n ingress-nginx -o wide
echo

echo "=== é›†ç¾¤æ£€æŸ¥å®Œæˆ ==="
EOF

chmod +x /usr/local/bin/check-k8s-cluster.sh

# è¿è¡Œæ£€æŸ¥
/usr/local/bin/check-k8s-cluster.sh
```

### 7.2 æµ‹è¯•åº”ç”¨éƒ¨ç½²

**åŸºäºå®é™…éƒ¨ç½²ç»éªŒçš„ç®€åŒ–æµ‹è¯•æ–¹æ¡ˆ**ï¼š

```bash
# éƒ¨ç½²ç®€åŒ–æµ‹è¯•åº”ç”¨ (é¿å…å¤æ‚çš„Ingressé…ç½®é—®é¢˜)
cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-test
  namespace: default
spec:
  replicas: 2
  selector:
    matchLabels:
      app: nginx-test
  template:
    metadata:
      labels:
        app: nginx-test
    spec:
      containers:
      - name: nginx
        image: nginx:1.25-alpine
        ports:
        - containerPort: 80
        resources:
          requests:
            cpu: "100m"
            memory: "128Mi"
          limits:
            cpu: "200m"
            memory: "256Mi"
---
apiVersion: v1
kind: Service
metadata:
  name: nginx-test-service
  namespace: default
spec:
  selector:
    app: nginx-test
  ports:
  - port: 80
    targetPort: 80
    nodePort: 30080  # å›ºå®šNodePortç«¯å£
  type: NodePort
EOF

# ç­‰å¾…æµ‹è¯•åº”ç”¨å¯åŠ¨
echo "ç­‰å¾…æµ‹è¯•åº”ç”¨å¯åŠ¨..."
kubectl wait --for=condition=ready pod -l app=nginx-test --timeout=120s

# éªŒè¯æµ‹è¯•åº”ç”¨
kubectl get pods -l app=nginx-test -o wide
kubectl get svc nginx-test-service

# æµ‹è¯•åº”ç”¨è®¿é—®
echo "=== æµ‹è¯•åº”ç”¨è®¿é—®æ–¹å¼ ==="
echo "æ–¹å¼1 - NodePortç›´æ¥è®¿é—®:"
echo "  è®¿é—®åœ°å€: http://192.168.110.88:30080"

echo "æ–¹å¼2 - ClusterIPå†…éƒ¨è®¿é—®:"
CLUSTER_IP=$(kubectl get svc nginx-test-service -o jsonpath='{.spec.clusterIP}')
echo "  å†…éƒ¨åœ°å€: http://$CLUSTER_IP"

# ç®€å•çš„è¿é€šæ€§æµ‹è¯•
echo "æ–¹å¼3 - è¿é€šæ€§æµ‹è¯•:"
if curl -s -o /dev/null -w "%{http_code}" http://192.168.110.88:30080 --connect-timeout 5; then
    echo "âœ… æµ‹è¯•åº”ç”¨è®¿é—®æ­£å¸¸"
else
    echo "âŒ æµ‹è¯•åº”ç”¨æ— æ³•è®¿é—®ï¼Œè¯·æ£€æŸ¥é…ç½®"
fi
```

### ğŸ“‹ é«˜çº§æµ‹è¯•ï¼šIngressèµ„æºéƒ¨ç½² (å¯é€‰)

å¦‚æœIngress Controlleré…ç½®æ­£å¸¸ï¼Œå¯ä»¥æµ‹è¯•IngressåŠŸèƒ½ï¼š

```bash
# åˆ›å»ºIngressèµ„æº (ä»…åœ¨Ingress Controlleræ­£å¸¸å·¥ä½œæ—¶ä½¿ç”¨)
cat <<EOF | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: nginx-test-ingress
  namespace: default
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  ingressClassName: nginx
  rules:
  - host: test.ai-platform.local
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: nginx-test-service
            port:
              number: 80
  - http:  # é»˜è®¤è§„åˆ™ï¼Œä¸éœ€è¦ç‰¹å®šhost
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: nginx-test-service
            port:
              number: 80
EOF

# éªŒè¯Ingressèµ„æº
kubectl get ingress nginx-test-ingress -o wide

# è·å–Ingressè®¿é—®ç«¯å£
INGRESS_HTTP_PORT=$(kubectl get svc ingress-nginx-controller -n ingress-nginx -o jsonpath='{.spec.ports[?(@.name=="http")].nodePort}')

echo "=== Ingressè®¿é—®æµ‹è¯• ==="
echo "æ–¹å¼1 - é€šè¿‡é»˜è®¤è§„åˆ™è®¿é—®:"
echo "  è®¿é—®åœ°å€: http://192.168.110.88:$INGRESS_HTTP_PORT"

echo "æ–¹å¼2 - é€šè¿‡åŸŸåè®¿é—® (éœ€è¦é…ç½®hosts):"
echo "  æ·»åŠ åˆ°hosts: 192.168.110.88 test.ai-platform.local"
echo "  è®¿é—®åœ°å€: http://test.ai-platform.local:$INGRESS_HTTP_PORT"

# æµ‹è¯•Ingressè®¿é—®
if curl -s -o /dev/null -w "%{http_code}" http://192.168.110.88:$INGRESS_HTTP_PORT --connect-timeout 5; then
    echo "âœ… Ingressè®¿é—®æ­£å¸¸"
else
    echo "âŒ Ingressè®¿é—®å¼‚å¸¸ï¼Œå»ºè®®ä½¿ç”¨NodePortæ–¹å¼"
fi
```

### ğŸ”§ æµ‹è¯•åº”ç”¨æ•…éšœæ’æŸ¥

```bash
# æµ‹è¯•åº”ç”¨æ•…éšœæ’æŸ¥è„šæœ¬
cat <<'EOF' > debug-test-app.sh
#!/bin/bash
echo "=== æµ‹è¯•åº”ç”¨æ•…éšœæ’æŸ¥ ==="

# 1. æ£€æŸ¥PodçŠ¶æ€
echo "1. PodçŠ¶æ€æ£€æŸ¥:"
kubectl get pods -l app=nginx-test -o wide

# 2. æ£€æŸ¥Podè¯¦ç»†ä¿¡æ¯
echo -e "\n2. Podè¯¦ç»†ä¿¡æ¯:"
for pod in $(kubectl get pods -l app=nginx-test -o name); do
    echo "æ£€æŸ¥ $pod:"
    kubectl describe $pod | grep -A 10 "Events:"
done

# 3. æ£€æŸ¥ServiceçŠ¶æ€
echo -e "\n3. ServiceçŠ¶æ€:"
kubectl get svc nginx-test-service -o wide
kubectl describe svc nginx-test-service

# 4. æ£€æŸ¥Endpoint
echo -e "\n4. EndpointçŠ¶æ€:"
kubectl get endpoints nginx-test-service

# 5. ç½‘ç»œè¿é€šæ€§æµ‹è¯•
echo -e "\n5. ç½‘ç»œè¿é€šæ€§æµ‹è¯•:"
NODE_PORT=$(kubectl get svc nginx-test-service -o jsonpath='{.spec.ports[0].nodePort}')
echo "NodePort: $NODE_PORT"

# æµ‹è¯•å†…éƒ¨è¿é€šæ€§
if kubectl get pods | grep -q nginx-test; then
    TEST_POD=$(kubectl get pods -l app=nginx-test -o jsonpath='{.items[0].metadata.name}')
    echo "å†…éƒ¨Podè¿é€šæ€§æµ‹è¯•:"
    kubectl exec $TEST_POD -- curl -s -o /dev/null -w "%{http_code}" http://nginx-test-service || echo "å†…éƒ¨è¿é€šå¤±è´¥"
fi

# æµ‹è¯•å¤–éƒ¨è¿é€šæ€§
echo "å¤–éƒ¨NodePortè¿é€šæ€§æµ‹è¯•:"
curl -s -o /dev/null -w "%{http_code}" http://192.168.110.88:$NODE_PORT --connect-timeout 5 || echo "å¤–éƒ¨è¿é€šå¤±è´¥"

echo -e "\n=== æ•…éšœæ’æŸ¥å®Œæˆ ==="
EOF

chmod +x debug-test-app.sh
./debug-test-app.sh
```

---

## 6. ğŸ”’ é›†ç¾¤å®‰å…¨é…ç½®

åŸºäºç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µçš„å®‰å…¨é…ç½®æŒ‡å—ï¼š

### 6.1 ç½‘ç»œå®‰å…¨ç­–ç•¥

```bash
# 1. é…ç½®åŸºç¡€ç½‘ç»œç­–ç•¥
cat <<EOF | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny-ingress
  namespace: default
spec:
  podSelector: {}
  policyTypes:
  - Ingress
---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-same-namespace
  namespace: default
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: default
EOF

# 2. ä¿æŠ¤kube-systemå‘½åç©ºé—´
cat <<EOF | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: deny-all
  namespace: kube-system
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress
EOF
```

### 6.2 RBACå®‰å…¨åŠ å›º

```bash
# 1. åˆ›å»ºå—é™çš„æœåŠ¡è´¦æˆ·
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: ServiceAccount
metadata:
  name: restricted-user
  namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: default
  name: pod-reader
rules:
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "watch", "list"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: read-pods
  namespace: default
subjects:
- kind: ServiceAccount
  name: restricted-user
  namespace: default
roleRef:
  kind: Role
  name: pod-reader
  apiGroup: rbac.authorization.k8s.io
EOF

# 2. å®¡è®¡ç°æœ‰æƒé™
kubectl auth can-i --list --as=system:serviceaccount:default:restricted-user
```

### 6.3 Podå®‰å…¨æ ‡å‡†

```bash
# 1. åº”ç”¨Podå®‰å…¨ç­–ç•¥
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Namespace
metadata:
  name: secure-namespace
  labels:
    pod-security.kubernetes.io/enforce: restricted
    pod-security.kubernetes.io/audit: restricted
    pod-security.kubernetes.io/warn: restricted
EOF

# 2. åˆ›å»ºå®‰å…¨ä¸Šä¸‹æ–‡ç¤ºä¾‹
cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: secure-app
  namespace: secure-namespace
spec:
  replicas: 1
  selector:
    matchLabels:
      app: secure-app
  template:
    metadata:
      labels:
        app: secure-app
    spec:
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        fsGroup: 2000
        seccompProfile:
          type: RuntimeDefault
      containers:
      - name: app
        image: nginx:1.25-alpine
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
          runAsNonRoot: true
          runAsUser: 1000
          capabilities:
            drop:
            - ALL
        resources:
          limits:
            cpu: "200m"
            memory: "256Mi"
          requests:
            cpu: "100m"
            memory: "128Mi"
        volumeMounts:
        - name: tmp
          mountPath: /tmp
        - name: cache
          mountPath: /var/cache/nginx
        - name: run
          mountPath: /var/run
      volumes:
      - name: tmp
        emptyDir: {}
      - name: cache
        emptyDir: {}
      - name: run
        emptyDir: {}
EOF
```

### 6.4 é›†ç¾¤è®¿é—®å®‰å…¨

```bash
# 1. é…ç½®kubectlè®¿é—®æƒé™
# åˆ›å»ºåªè¯»ç”¨æˆ·
openssl genrsa -out readonly-user.key 2048
openssl req -new -key readonly-user.key -out readonly-user.csr -subj "/CN=readonly-user/O=viewers"

# ç”Ÿæˆè¯ä¹¦ (éœ€è¦CAè¯ä¹¦)
sudo openssl x509 -req -in readonly-user.csr -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out readonly-user.crt -days 365

# é…ç½®kubectl context
kubectl config set-credentials readonly-user --client-certificate=readonly-user.crt --client-key=readonly-user.key
kubectl config set-context readonly-context --cluster=kubernetes --user=readonly-user

# 2. åˆ›å»ºåªè¯»ClusterRole
cat <<EOF | kubectl apply -f -
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: readonly-role
rules:
- apiGroups: [""]
  resources: ["pods", "services", "nodes", "namespaces"]
  verbs: ["get", "watch", "list"]
- apiGroups: ["apps"]
  resources: ["deployments", "replicasets"]
  verbs: ["get", "watch", "list"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: readonly-binding
subjects:
- kind: User
  name: readonly-user
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: ClusterRole
  name: readonly-role
  apiGroup: rbac.authorization.k8s.io
EOF
```

### 6.5 å®šæœŸå®‰å…¨æ£€æŸ¥è„šæœ¬

```bash
# åˆ›å»ºå®šæœŸå®‰å…¨æ£€æŸ¥è„šæœ¬
cat > security-check.sh << 'EOF'
#!/bin/bash
echo "=== Kubernetesé›†ç¾¤å®‰å…¨æ£€æŸ¥ ==="
echo "æ£€æŸ¥æ—¶é—´: $(date)"
echo

# 1. æ£€æŸ¥ç‰¹æƒPod
echo "1. æ£€æŸ¥ç‰¹æƒPod:"
kubectl get pods --all-namespaces -o jsonpath='{range .items[*]}{.metadata.namespace}{"\t"}{.metadata.name}{"\t"}{.spec.securityContext.privileged}{"\n"}{end}' | grep true || echo "æ— ç‰¹æƒPod"
echo

# 2. æ£€æŸ¥ç½‘ç»œç­–ç•¥
echo "2. æ£€æŸ¥ç½‘ç»œç­–ç•¥:"
kubectl get networkpolicies --all-namespaces
echo

# 3. æ£€æŸ¥æœåŠ¡è´¦æˆ·æƒé™
echo "3. æ£€æŸ¥å±é™©çš„ClusterRoleBinding:"
kubectl get clusterrolebinding -o json | jq -r '.items[] | select(.roleRef.name=="cluster-admin") | .metadata.name + " -> " + (.subjects[]?.name // "N/A")'
echo

# 4. æ£€æŸ¥æœªåŠ å¯†çš„Secret
echo "4. æ£€æŸ¥Secretæ•°é‡:"
kubectl get secrets --all-namespaces --no-headers | wc -l
echo

# 5. æ£€æŸ¥Podå®‰å…¨ä¸Šä¸‹æ–‡
echo "5. æ£€æŸ¥è¿è¡Œä¸ºrootçš„Pod:"
kubectl get pods --all-namespaces -o jsonpath='{range .items[*]}{.metadata.namespace}{"\t"}{.metadata.name}{"\t"}{.spec.securityContext.runAsUser}{"\n"}{end}' | grep -E '\t0$|\t$' || echo "æ— root Pod"
echo

echo "=== å®‰å…¨æ£€æŸ¥å®Œæˆ ==="
EOF

chmod +x security-check.sh
```

---

### ğŸ—‘ï¸ æ¸…ç†æµ‹è¯•èµ„æº

```bash
# æ¸…ç†æµ‹è¯•åº”ç”¨èµ„æº
echo "æ¸…ç†æµ‹è¯•åº”ç”¨èµ„æº..."
kubectl delete deployment nginx-test
kubectl delete service nginx-test-service
kubectl delete ingress nginx-test-ingress 2>/dev/null || true

echo "âœ… æµ‹è¯•èµ„æºæ¸…ç†å®Œæˆ"
```

## 8. ä¸‹ä¸€æ­¥éƒ¨ç½²æŒ‡å¼•

Kubernetesé›†ç¾¤éƒ¨ç½²å®Œæˆåï¼Œå¯ä»¥ç»§ç»­éƒ¨ç½²å­˜å‚¨å’Œèµ„æºç®¡ç†ï¼š

> ğŸ“‹ **ä¸‹ä¸€æ­¥**: [Kuberneteså­˜å‚¨ç³»ç»Ÿ](./03_storage_systems_kubernetes.md)
> 
> è¯¥æ–‡æ¡£åŒ…å«ï¼š
> - âœ… æŒä¹…åŒ–å­˜å‚¨é…ç½®
> - âœ… StorageClassè®¾ç½®
> - âœ… æ•°æ®å¤‡ä»½ç­–ç•¥

> ğŸ“‹ **åŒæ—¶è¿›è¡Œ**: [Kubernetesèµ„æºç®¡ç†](./04_resource_management_kubernetes.md)
> 
> è¯¥æ–‡æ¡£åŒ…å«ï¼š
> - âœ… èµ„æºé…é¢ç®¡ç†
> - âœ… å‘½åç©ºé—´è§„åˆ’
> - âœ… ç›‘æ§å’Œæ—¥å¿—

## ğŸ“ é‡è¦è¿ç»´è¯´æ˜

### é›†ç¾¤ç»´æŠ¤

```bash
# å®šæœŸæ£€æŸ¥é›†ç¾¤å¥åº·çŠ¶æ€
kubectl get nodes
kubectl get pods -A

# æŸ¥çœ‹é›†ç¾¤äº‹ä»¶
kubectl get events --sort-by=.metadata.creationTimestamp

# æ¸…ç†å®Œæˆçš„Pod
kubectl delete pods --field-selector=status.phase==Succeeded -A

# æ›´æ–°é›†ç¾¤è¯ä¹¦ (è¯ä¹¦å³å°†è¿‡æœŸæ—¶)
sudo kubeadm certs renew all
```

### æ•…éšœæ’æŸ¥

```bash
# æŸ¥çœ‹Podæ—¥å¿—
kubectl logs <pod-name> -n <namespace>

# æŸ¥çœ‹Podè¯¦ç»†ä¿¡æ¯
kubectl describe pod <pod-name> -n <namespace>

# æŸ¥çœ‹èŠ‚ç‚¹è¯¦ç»†ä¿¡æ¯
kubectl describe node <node-name>

# æŸ¥çœ‹é›†ç¾¤ç»„ä»¶æ—¥å¿—
sudo journalctl -u kubelet -f
```

---
*æ–‡æ¡£æ›´æ–°æ—¶é—´: 2025å¹´1æœˆ7æ—¥ - Kubernetes 1.28.8é›†ç¾¤éƒ¨ç½²*  
*åŸºäºå®é™…ç¯å¢ƒé…ç½®: Ubuntu 24.04 LTS, IP: 192.168.110.88*  
*å®é™…éƒ¨ç½²æ—¶é—´: 2-3å°æ—¶ (åŒ…å«é—®é¢˜æ’æŸ¥)*  
*éƒ¨ç½²ç»éªŒæ€»ç»“: FlannelæˆåŠŸéƒ¨ç½²ï¼ŒIngress Controller RBACæƒé™ä¿®å¤ï¼Œadmission webhooké—®é¢˜è§£å†³*

## ğŸ† éƒ¨ç½²æˆåŠŸéªŒè¯æ¸…å•

### âœ… é›†ç¾¤åŸºç¡€ç»„ä»¶éªŒè¯

```bash
# è¿è¡Œå®Œæ•´éªŒè¯è„šæœ¬
cat <<'EOF' > final-verification.sh
#!/bin/bash
echo "=== Kubernetes é›†ç¾¤éƒ¨ç½²æˆåŠŸéªŒè¯ ==="
echo "éªŒè¯æ—¶é—´: $(date)"
echo

# 1. èŠ‚ç‚¹çŠ¶æ€éªŒè¯
echo "âœ… 1. èŠ‚ç‚¹çŠ¶æ€éªŒè¯:"
kubectl get nodes -o wide
NODE_STATUS=$(kubectl get nodes --no-headers | awk '{print $2}')
if [[ "$NODE_STATUS" == "Ready" ]]; then
    echo "âœ… èŠ‚ç‚¹çŠ¶æ€: Ready"
else
    echo "âŒ èŠ‚ç‚¹çŠ¶æ€: $NODE_STATUS"
fi
echo

# 2. ç³»ç»ŸPodçŠ¶æ€éªŒè¯
echo "âœ… 2. ç³»ç»ŸPodçŠ¶æ€éªŒè¯:"
kubectl get pods -n kube-system -o wide
SYSTEM_PODS_RUNNING=$(kubectl get pods -n kube-system --no-headers | grep -c "Running")
TOTAL_SYSTEM_PODS=$(kubectl get pods -n kube-system --no-headers | wc -l)
echo "è¿è¡Œä¸­çš„ç³»ç»ŸPod: $SYSTEM_PODS_RUNNING/$TOTAL_SYSTEM_PODS"
echo

# 3. ç½‘ç»œæ’ä»¶éªŒè¯
echo "âœ… 3. ç½‘ç»œæ’ä»¶éªŒè¯:"
kubectl get pods -n kube-flannel -o wide 2>/dev/null || echo "Flannelæœªå®‰è£…"
FLANNEL_PODS_RUNNING=$(kubectl get pods -n kube-flannel --no-headers 2>/dev/null | grep -c "Running" || echo "0")
echo "Flannel Podè¿è¡ŒçŠ¶æ€: $FLANNEL_PODS_RUNNING"
echo

# 4. Ingress ControlleréªŒè¯
echo "âœ… 4. Ingress ControlleréªŒè¯:"
kubectl get pods -n ingress-nginx -o wide
INGRESS_PODS_RUNNING=$(kubectl get pods -n ingress-nginx --no-headers 2>/dev/null | grep -c "Running" || echo "0")
echo "Ingress Controllerè¿è¡ŒçŠ¶æ€: $INGRESS_PODS_RUNNING"

# è·å–Ingressç«¯å£ä¿¡æ¯
HTTP_PORT=$(kubectl get svc ingress-nginx-controller -n ingress-nginx -o jsonpath='{.spec.ports[?(@.name=="http")].nodePort}' 2>/dev/null || echo "æœªé…ç½®")
HTTPS_PORT=$(kubectl get svc ingress-nginx-controller -n ingress-nginx -o jsonpath='{.spec.ports[?(@.name=="https")].nodePort}' 2>/dev/null || echo "æœªé…ç½®")
echo "HTTPç«¯å£: $HTTP_PORT"
echo "HTTPSç«¯å£: $HTTPS_PORT"
echo

# 5. DNSæœåŠ¡éªŒè¯
echo "âœ… 5. DNSæœåŠ¡éªŒè¯:"
kubectl get pods -n kube-system -l k8s-app=kube-dns -o wide
COREDNS_PODS_RUNNING=$(kubectl get pods -n kube-system -l k8s-app=kube-dns --no-headers | grep -c "Running")
echo "CoreDNS Podè¿è¡ŒçŠ¶æ€: $COREDNS_PODS_RUNNING"
echo

# 6. ç½‘ç»œè¿é€šæ€§éªŒè¯
echo "âœ… 6. ç½‘ç»œè¿é€šæ€§éªŒè¯:"
# åˆ›å»ºä¸´æ—¶æµ‹è¯•Pod
kubectl run test-pod --image=busybox:1.35 --rm -i --restart=Never --command -- /bin/sh -c "nslookup kubernetes.default" 2>/dev/null && echo "âœ… DNSè§£ææ­£å¸¸" || echo "âŒ DNSè§£æå¤±è´¥"
echo

# 7. æœ€ç»ˆæ€»ç»“
echo "=== éƒ¨ç½²æˆåŠŸæ ‡å¿—æ£€æŸ¥ ==="
SUCCESS_COUNT=0
TOTAL_CHECKS=6

if [[ "$NODE_STATUS" == "Ready" ]]; then
    echo "âœ… èŠ‚ç‚¹çŠ¶æ€æ­£å¸¸"
    ((SUCCESS_COUNT++))
else
    echo "âŒ èŠ‚ç‚¹çŠ¶æ€å¼‚å¸¸"
fi

if [[ $SYSTEM_PODS_RUNNING -ge 5 ]]; then
    echo "âœ… ç³»ç»ŸPodè¿è¡Œæ­£å¸¸"
    ((SUCCESS_COUNT++))
else
    echo "âŒ ç³»ç»ŸPodè¿è¡Œå¼‚å¸¸"
fi

if [[ $FLANNEL_PODS_RUNNING -ge 1 ]]; then
    echo "âœ… ç½‘ç»œæ’ä»¶è¿è¡Œæ­£å¸¸"
    ((SUCCESS_COUNT++))
else
    echo "âŒ ç½‘ç»œæ’ä»¶è¿è¡Œå¼‚å¸¸"
fi

if [[ $COREDNS_PODS_RUNNING -ge 1 ]]; then
    echo "âœ… DNSæœåŠ¡è¿è¡Œæ­£å¸¸"
    ((SUCCESS_COUNT++))
else
    echo "âŒ DNSæœåŠ¡è¿è¡Œå¼‚å¸¸"
fi

if [[ $INGRESS_PODS_RUNNING -ge 1 ]]; then
    echo "âœ… Ingress Controllerè¿è¡Œæ­£å¸¸"
    ((SUCCESS_COUNT++))
else
    echo "âŒ Ingress Controllerè¿è¡Œå¼‚å¸¸"
fi

if [[ "$HTTP_PORT" != "æœªé…ç½®" && "$HTTP_PORT" != "" ]]; then
    echo "âœ… Ingressç«¯å£é…ç½®æ­£å¸¸"
    ((SUCCESS_COUNT++))
else
    echo "âŒ Ingressç«¯å£é…ç½®å¼‚å¸¸"
fi

echo
echo "=== æœ€ç»ˆéƒ¨ç½²ç»“æœ ==="
echo "æˆåŠŸé¡¹ç›®: $SUCCESS_COUNT/$TOTAL_CHECKS"

if [[ $SUCCESS_COUNT -eq $TOTAL_CHECKS ]]; then
    echo "ğŸ‰ Kubernetesé›†ç¾¤éƒ¨ç½²å®Œå…¨æˆåŠŸï¼"
    echo "ğŸ“‹ è®¿é—®ä¿¡æ¯:"
    echo "   é›†ç¾¤åœ°å€: https://192.168.110.88:6443"
    echo "   HTTPè®¿é—®: http://192.168.110.88:$HTTP_PORT"
    echo "   HTTPSè®¿é—®: https://192.168.110.88:$HTTPS_PORT"
    echo "âœ… å¯ä»¥è¿›è¡Œä¸‹ä¸€é˜¶æ®µéƒ¨ç½²"
elif [[ $SUCCESS_COUNT -ge 4 ]]; then
    echo "âš ï¸  Kubernetesé›†ç¾¤åŸºæœ¬å¯ç”¨ï¼Œå­˜åœ¨éƒ¨åˆ†é—®é¢˜"
    echo "ğŸ”§ å»ºè®®è§£å†³åç»­é—®é¢˜åå†è¿›è¡Œä¸‹ä¸€é˜¶æ®µéƒ¨ç½²"
else
    echo "âŒ Kubernetesé›†ç¾¤éƒ¨ç½²å­˜åœ¨é‡å¤§é—®é¢˜"
    echo "ğŸš¨ éœ€è¦æ’æŸ¥å’Œè§£å†³é—®é¢˜åæ‰èƒ½ç»§ç»­"
fi
echo
EOF

chmod +x final-verification.sh
./final-verification.sh
```

### ğŸ“Š å®é™…éƒ¨ç½²æ—¶é—´ç»Ÿè®¡

åŸºäºçœŸå®éƒ¨ç½²ç»éªŒçš„æ—¶é—´åˆ†é…ï¼š

| é˜¶æ®µ | é¢„è®¡æ—¶é—´ | å®é™…æ—¶é—´ | ä¸»è¦ä»»åŠ¡ |
|------|---------|---------|----------|
| **åŸºç¡€ç¯å¢ƒå‡†å¤‡** | 20-30åˆ†é’Ÿ | 15åˆ†é’Ÿ | containerdé…ç½®ã€é•œåƒæºè®¾ç½® |
| **Kubernetesç»„ä»¶å®‰è£…** | 20-30åˆ†é’Ÿ | 25åˆ†é’Ÿ | kubeadmã€kubeletã€kubectlå®‰è£… |
| **é›†ç¾¤åˆå§‹åŒ–** | 15-25åˆ†é’Ÿ | 30åˆ†é’Ÿ | åŒ…å«pauseå®¹å™¨é—®é¢˜è§£å†³ |
| **ç½‘ç»œæ’ä»¶éƒ¨ç½²** | 10-20åˆ†é’Ÿ | 45åˆ†é’Ÿ | Flanneléƒ¨ç½²å’Œé…ç½®éªŒè¯ |
| **Ingress Controlleréƒ¨ç½²** | 15-30åˆ†é’Ÿ | 60åˆ†é’Ÿ | åŒ…å«RBACæƒé™å’Œwebhooké—®é¢˜è§£å†³ |
| **æµ‹è¯•å’ŒéªŒè¯** | 10-20åˆ†é’Ÿ | 30åˆ†é’Ÿ | å®Œæ•´åŠŸèƒ½éªŒè¯ |
| **é—®é¢˜æ’æŸ¥å’Œæ–‡æ¡£** | - | 45åˆ†é’Ÿ | å®é™…é—®é¢˜è§£å†³å’Œç»éªŒæ€»ç»“ |
| **æ€»è®¡** | 1-1.5å°æ—¶ | **3.5å°æ—¶** | åŒ…å«å®Œæ•´é—®é¢˜è§£å†³è¿‡ç¨‹ |

### ğŸ¯ å…³é”®æˆåŠŸå› ç´ 

1. **é•œåƒæ‹‰å–ä¼˜åŒ–**: ä½¿ç”¨å›½å†…é•œåƒæºï¼Œé¢„æ‹‰å–å…³é”®é•œåƒ
2. **ç½‘ç»œé…ç½®ä¸€è‡´æ€§**: Pod CIDRé…ç½®å¿…é¡»åœ¨æ‰€æœ‰ç»„ä»¶ä¸­ä¿æŒä¸€è‡´
3. **æƒé™é…ç½®å®Œæ•´æ€§**: Ingress Controlleréœ€è¦å®Œæ•´çš„RBACæƒé™
4. **Webhookç®€åŒ–**: åœ¨å—é™ç¯å¢ƒä¸­åˆ é™¤admission webhook
5. **åˆ†æ­¥éªŒè¯**: æ¯ä¸ªé˜¶æ®µå®Œæˆåè¿›è¡ŒéªŒè¯ï¼Œé¿å…åç»­é—®é¢˜ç§¯ç´¯

## ğŸ”— ç›¸å…³æ–‡æ¡£é“¾æ¥

- [å®¹å™¨åŒ–å¹³å°éƒ¨ç½²](./01_container_platform_setup.md) - Dockerå’Œcontainerdé…ç½®
- [Kuberneteså­˜å‚¨ç³»ç»Ÿ](./03_storage_systems_kubernetes.md) - æŒä¹…åŒ–å­˜å‚¨é…ç½®  
- [Kubernetesèµ„æºç®¡ç†](./04_resource_management_kubernetes.md) - èµ„æºé…é¢å’Œç›‘æ§
- [æ•°æ®åº“éƒ¨ç½²æŒ‡å—](../02_server_deployment/05_database_deployment/) - PostgreSQLã€MongoDBç­‰æ•°æ®åº“
- [åº”ç”¨éƒ¨ç½²æ¦‚è§ˆ](../03_application_deployment/00_application_overview.md) - å®Œæ•´åº”ç”¨å †æ ˆéƒ¨ç½²

## ğŸ“ æŠ€æœ¯æ”¯æŒä¸æ•…éšœæ’æŸ¥

### å¸¸è§é—®é¢˜å¿«é€Ÿè¯Šæ–­

```bash
# å¿«é€Ÿé›†ç¾¤å¥åº·æ£€æŸ¥è„šæœ¬
cat > check-cluster-health.sh << 'EOF'
#!/bin/bash
echo "=== Kubernetes é›†ç¾¤å¿«é€Ÿå¥åº·æ£€æŸ¥ ==="
echo "æ£€æŸ¥æ—¶é—´: $(date)"
echo

# 1. èŠ‚ç‚¹çŠ¶æ€
echo "1. èŠ‚ç‚¹çŠ¶æ€:"
kubectl get nodes -o wide
echo

# 2. å…³é”®ç³»ç»ŸPodçŠ¶æ€
echo "2. ç³»ç»ŸPodçŠ¶æ€:"
kubectl get pods -n kube-system -o wide
echo

# 3. ç½‘ç»œæ’ä»¶çŠ¶æ€
echo "3. ç½‘ç»œæ’ä»¶çŠ¶æ€:"
kubectl get pods -n kube-flannel -o wide 2>/dev/null || echo "Flannelæœªå®‰è£…"
kubectl get pods -n calico-system -o wide 2>/dev/null || echo "Calicoæœªå®‰è£…"
echo

# 4. DNSæœåŠ¡çŠ¶æ€
echo "4. DNSæœåŠ¡çŠ¶æ€:"
kubectl get pods -n kube-system -l k8s-app=kube-dns -o wide
echo

# 5. æœ€è¿‘äº‹ä»¶
echo "5. æœ€è¿‘é›†ç¾¤äº‹ä»¶:"
kubectl get events --sort-by=.metadata.creationTimestamp | tail -10
echo

# 6. èµ„æºä½¿ç”¨æ¦‚è§ˆ
echo "6. èµ„æºä½¿ç”¨æ¦‚è§ˆ:"
kubectl top nodes 2>/dev/null || echo "Metrics Serveræœªå®‰è£…ï¼Œæ— æ³•æ˜¾ç¤ºèµ„æºä½¿ç”¨æƒ…å†µ"

echo "=== å¥åº·æ£€æŸ¥å®Œæˆ ==="
EOF

chmod +x check-cluster-health.sh
./check-cluster-health.sh
```

### æ•…éšœæ’æŸ¥è”ç³»æ–¹å¼

å¦‚æœåœ¨éƒ¨ç½²è¿‡ç¨‹ä¸­é‡åˆ°æ— æ³•è§£å†³çš„é—®é¢˜ï¼Œè¯·å‚è€ƒï¼š

1. **æ–‡æ¡£å†…æ•…éšœæ’æŸ¥**: æŸ¥çœ‹æœ¬æ–‡æ¡£"å®é™…éƒ¨ç½²é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ"ç« èŠ‚
2. **å®˜æ–¹æ–‡æ¡£**: 
   - [Kuberneteså®˜æ–¹æ–‡æ¡£](https://kubernetes.io/docs/)
   - [Flannelé¡¹ç›®æ–‡æ¡£](https://github.com/flannel-io/flannel)
   - [Calicoé¡¹ç›®æ–‡æ¡£](https://docs.projectcalico.org/)
3. **æ—¥å¿—æ”¶é›†**: ä½¿ç”¨ä¸Šè¿°å¥åº·æ£€æŸ¥è„šæœ¬æ”¶é›†è¯¦ç»†ä¿¡æ¯
4. **ç¤¾åŒºæ”¯æŒ**: Kubernetesç¤¾åŒºå’Œç›¸å…³é¡¹ç›®çš„GitHub Issues

### éƒ¨ç½²æˆåŠŸæ ‡å¿—

é›†ç¾¤éƒ¨ç½²æˆåŠŸçš„éªŒè¯æ ‡å‡†ï¼š

- âœ… æ‰€æœ‰èŠ‚ç‚¹çŠ¶æ€ä¸º`Ready`
- âœ… æ‰€æœ‰kube-system PodçŠ¶æ€ä¸º`Running`
- âœ… ç½‘ç»œæ’ä»¶PodçŠ¶æ€ä¸º`Running`
- âœ… CoreDNS Podæ­£å¸¸è¿è¡Œ
- âœ… Podé—´ç½‘ç»œé€šä¿¡æ­£å¸¸
- âœ… DNSè§£æåŠŸèƒ½æ­£å¸¸

å½“æ‰€æœ‰æ ‡å¿—éƒ½æ»¡è¶³æ—¶ï¼Œå³å¯è¿›è¡Œä¸‹ä¸€é˜¶æ®µçš„éƒ¨ç½²å·¥ä½œã€‚

---

## ğŸš¨ å¸¸è§é”™è¯¯é€ŸæŸ¥è¡¨

åŸºäºå®é™…éƒ¨ç½²ç»éªŒæ•´ç†çš„å¿«é€Ÿé—®é¢˜è§£å†³æŒ‡å—ï¼š

### ğŸ”¥ è¶…é«˜é¢‘é”™è¯¯ (90%+é‡åˆ°)

| é”™è¯¯ç°è±¡ | å¯èƒ½åŸå›  | å¿«é€Ÿè§£å†³æ–¹æ¡ˆ | éªŒè¯æ–¹æ³• |
|---------|---------|-------------|---------|
| **èŠ‚ç‚¹NotReady** | ç½‘ç»œæ’ä»¶æœªå°±ç»ª | `kubectl apply -f kube-flannel.yml` | `kubectl get nodes` |
| **é•œåƒæ‹‰å–è¶…æ—¶** | ç½‘ç»œé—®é¢˜/å¢™ | é…ç½®å›½å†…é•œåƒæº | `crictl images` |
| **pause:3.9æ‹‰å–å¤±è´¥** | pauseå®¹å™¨é—®é¢˜ | é¢„æ‹‰å–å¹¶é‡æ ‡è®° | `crictl images \| grep pause` |
| **kubeadm initè¶…æ—¶** | swapæœªå…³é—­ | `swapoff -a` | `free -h` |
| **Ingress Webhooké”™è¯¯** | å‡†å…¥æ§åˆ¶å™¨é—®é¢˜ | åˆ é™¤validatingwebhook | `kubectl get validatingwebhook` |

### ğŸ“‹ ç½‘ç»œç›¸å…³é”™è¯¯

| é”™è¯¯ç°è±¡ | ç—‡çŠ¶ | è§£å†³æ–¹æ¡ˆ |
|---------|------|---------|
| **Podé—´æ— æ³•é€šä¿¡** | pingå¤±è´¥ | æ£€æŸ¥ç½‘ç»œæ’ä»¶ã€CIDRé…ç½® |
| **DNSè§£æå¤±è´¥** | nslookupå¤±è´¥ | é‡å¯CoreDNSï¼š`kubectl rollout restart deployment coredns -n kube-system` |
| **Serviceè®¿é—®å¼‚å¸¸** | æœåŠ¡ä¸å¯è¾¾ | æ£€æŸ¥kube-proxyã€é˜²ç«å¢™è§„åˆ™ |
| **NodePortæ— æ³•è®¿é—®** | å¤–éƒ¨è®¿é—®å¤±è´¥ | æ£€æŸ¥é˜²ç«å¢™ç«¯å£å¼€æ”¾ |

### ğŸ› ï¸ å®¹å™¨è¿è¡Œæ—¶é”™è¯¯

| é”™è¯¯ç°è±¡ | å¸¸è§åŸå›  | è§£å†³å‘½ä»¤ |
|---------|---------|---------|
| **containerdè¿æ¥å¤±è´¥** | socketè·¯å¾„é”™è¯¯ | `--cri-socket=unix:///var/run/containerd/containerd.sock` |
| **SystemdCgroupé”™è¯¯** | cgroupé…ç½®ä¸å½“ | ä¿®æ”¹`/etc/containerd/config.toml` |
| **è¿è¡Œæ—¶å“åº”è¶…æ—¶** | containerdæ€§èƒ½é—®é¢˜ | `systemctl restart containerd` |

### âš¡ ä¸€é”®ä¿®å¤è„šæœ¬

```bash
# åˆ›å»ºåº”æ€¥ä¿®å¤è„šæœ¬
cat > emergency-fix.sh << 'EOF'
#!/bin/bash
echo "=== Kubernetes åº”æ€¥ä¿®å¤è„šæœ¬ ==="

# 1. é‡å¯å…³é”®æœåŠ¡
echo "é‡å¯containerd..."
sudo systemctl restart containerd

echo "é‡å¯kubelet..."
sudo systemctl restart kubelet

# 2. æ¸…ç†æœ‰é—®é¢˜çš„Pod
echo "æ¸…ç†Evicted Pod..."
kubectl get pods --all-namespaces | grep Evicted | awk '{print $2 " -n " $1}' | xargs -r kubectl delete pod

# 3. æ£€æŸ¥ç½‘ç»œæ’ä»¶
echo "æ£€æŸ¥ç½‘ç»œæ’ä»¶çŠ¶æ€..."
kubectl get pods -n kube-flannel 2>/dev/null || echo "Flannelæœªå®‰è£…"
kubectl get pods -n calico-system 2>/dev/null || echo "Calicoæœªå®‰è£…"

# 4. é‡å¯CoreDNS
echo "é‡å¯CoreDNS..."
kubectl rollout restart deployment coredns -n kube-system

# 5. æ˜¾ç¤ºé›†ç¾¤çŠ¶æ€
echo "=== ä¿®å¤åçŠ¶æ€ ==="
kubectl get nodes
kubectl get pods -n kube-system

echo "=== ä¿®å¤å®Œæˆ ==="
EOF

chmod +x emergency-fix.sh
```

### ğŸ“ æŠ€æœ¯æ”¯æŒ

**éƒ¨ç½²é‡åˆ°é—®é¢˜æ—¶çš„å»ºè®®æµç¨‹ï¼š**

1. **ğŸ” æ£€æŸ¥é”™è¯¯ç±»å‹**: å¯¹ç…§ä¸Šè¿°é€ŸæŸ¥è¡¨å¿«é€Ÿå®šä½
2. **ğŸ“‹ æ”¶é›†ä¿¡æ¯**: è¿è¡Œå¥åº·æ£€æŸ¥è„šæœ¬
3. **ğŸ› ï¸ å°è¯•ä¿®å¤**: ä½¿ç”¨å¯¹åº”çš„è§£å†³æ–¹æ¡ˆ
4. **ğŸš¨ åº”æ€¥å¤„ç†**: è¿è¡Œä¸€é”®ä¿®å¤è„šæœ¬
5. **ğŸ“– æŸ¥é˜…æ–‡æ¡£**: å‚è€ƒå…·ä½“ç« èŠ‚çš„è¯¦ç»†è¯´æ˜

**ğŸ“„ æ–‡æ¡£ç‰ˆæœ¬ä¿¡æ¯**
- æ–‡æ¡£ç‰ˆæœ¬: v2.1
- æœ€åæ›´æ–°: 2025å¹´6æœˆ5æ—¥
- åŸºäºå®é™…éƒ¨ç½²: Ubuntu 24.04 LTS + Kubernetes 1.28.8
- éƒ¨ç½²ç¯å¢ƒ: ç”Ÿäº§çº§ä¼ä¸šç¯å¢ƒ
- éªŒè¯çŠ¶æ€: âœ… å®Œå…¨éªŒè¯é€šè¿‡
